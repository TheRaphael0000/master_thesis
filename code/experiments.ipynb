{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std Python Lib\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "# Requirements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import wilcoxon\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Project\n",
    "import distances\n",
    "import compressions\n",
    "import s_curves\n",
    "\n",
    "from corpus import brunet\n",
    "from corpus import oxquarry\n",
    "from corpus import st_jean\n",
    "from corpus import pan16\n",
    "\n",
    "\n",
    "from rank_list_fusion import fusion_z_score\n",
    "from rank_list_fusion import fusion_regression_training\n",
    "from rank_list_fusion import fusion_regression\n",
    "\n",
    "from evaluate import evaluate_linking\n",
    "from evaluate import evaluate_clustering\n",
    "\n",
    "from linking import compute_links\n",
    "from linking import most_frequent_word\n",
    "\n",
    "from clustering import supervised_clustering_training\n",
    "from clustering import supervised_clustering_predict\n",
    "from clustering import unsupervised_clustering\n",
    "from clustering import clustering_at_every_n_clusters\n",
    "\n",
    "from misc import sign_test\n",
    "from misc import first_letters_cut\n",
    "from misc import word_n_grams\n",
    "from misc import last_letters_cut\n",
    "from misc import sigmoid\n",
    "from misc import sigmoid_r\n",
    "from misc import compute_r\n",
    "from misc import normalize\n",
    "from misc import rank_list_distance\n",
    "from misc import dataset_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, floatmode=\"fixed\", suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Oxquarry\n",
      "Loading Brunet\n",
      "Loading St-Jean A\n",
      "Loading St-Jean B\n",
      "Loading St-Jean\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Oxquarry\")\n",
    "info_oxquarry, X_token_oxquarry, Y_oxquarry = oxquarry.parse()\n",
    "print(\"Loading Brunet\")\n",
    "info_brunet, X_lemma_brunet, X_token_brunet, Y_brunet = brunet.parse()\n",
    "print(\"Loading St-Jean A\")\n",
    "info_st_jean_A, X_pos_st_jean_A, X_lemma_st_jean_A, X_token_st_jean_A, Y_st_jean_A = st_jean.parse_A()\n",
    "print(\"Loading St-Jean B\")\n",
    "info_st_jean_B, X_pos_st_jean_B, X_lemma_st_jean_B, X_token_st_jean_B, Y_st_jean_B = st_jean.parse_B()\n",
    "print(\"Loading St-Jean\")\n",
    "info_st_jean, X_pos_st_jean, X_lemma_st_jean, X_token_st_jean, Y_st_jean = st_jean.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name, Language, authors, texts, r, true_links, links, true_links_ratio, mean_length\n",
      "Oxquarry EN 9 52 0.173 160 1326 0.121 11650 3.819\n",
      "Brunet FR 11 44 0.25 66 946 0.07 9778 4.013\n",
      "St-Jean FR 30 200 0.15 670 19900 0.034 11533 3.928\n",
      "St-Jean A 001-100 FR 17 100 0.17 330 4950 0.067 11552 3.949\n",
      "St-Jean B 101-200 FR 19 100 0.19 258 4950 0.052 11513 3.907\n",
      "PAN16 en problem001 35 50 0.7 26 1225 0.021 872 4.161\n",
      "PAN16 en problem002 25 50 0.5 75 1225 0.061 881 4.118\n",
      "PAN16 en problem003 43 50 0.86 8 1225 0.007 867 4.113\n",
      "PAN16 en problem004 55 80 0.688 36 3160 0.011 1125 4.283\n",
      "PAN16 en problem005 70 80 0.875 12 3160 0.004 1252 4.318\n",
      "PAN16 en problem006 40 80 0.5 65 3160 0.021 1180 4.305\n",
      "PAN16 nl problem007 51 57 0.895 7 1596 0.004 1261 4.582\n",
      "PAN16 nl problem008 28 57 0.491 76 1596 0.048 1533 4.648\n",
      "PAN16 nl problem009 40 57 0.702 30 1596 0.019 1184 4.613\n",
      "PAN16 nl problem010 54 100 0.54 77 4950 0.016 145 4.41\n",
      "PAN16 nl problem011 67 100 0.67 46 4950 0.009 152 4.393\n",
      "PAN16 nl problem012 91 100 0.91 10 4950 0.002 142 4.386\n",
      "PAN16 gr problem013 28 55 0.509 38 1485 0.026 903 4.596\n",
      "PAN16 gr problem014 38 55 0.691 25 1485 0.017 895 4.633\n",
      "PAN16 gr problem015 48 55 0.873 8 1485 0.005 879 4.62\n",
      "PAN16 gr problem016 50 55 0.909 6 1485 0.004 653 4.318\n",
      "PAN16 gr problem017 28 55 0.509 55 1485 0.037 781 4.34\n",
      "PAN16 gr problem018 40 55 0.727 19 1485 0.013 707 4.298\n",
      "PAN16 en problem001 50 70 0.714 33 2415 0.014 666 4.327\n",
      "PAN16 en problem002 35 70 0.5 113 2415 0.047 678 4.241\n",
      "PAN16 en problem003 64 70 0.914 7 2415 0.003 663 4.324\n",
      "PAN16 en problem004 58 80 0.725 30 3160 0.009 1168 4.284\n",
      "PAN16 en problem005 72 80 0.9 10 3160 0.003 1186 4.301\n",
      "PAN16 en problem006 42 80 0.525 68 3160 0.022 1156 4.287\n",
      "PAN16 nl problem007 42 57 0.737 24 1596 0.015 1365 4.63\n",
      "PAN16 nl problem008 50 57 0.877 8 1596 0.005 1377 4.576\n",
      "PAN16 nl problem009 30 57 0.526 65 1596 0.041 1110 4.561\n",
      "PAN16 nl problem010 88 100 0.88 16 4950 0.003 171 4.5\n",
      "PAN16 nl problem011 51 100 0.51 76 4950 0.015 169 4.448\n",
      "PAN16 nl problem012 71 100 0.71 37 4950 0.007 175 4.444\n",
      "PAN16 gr problem013 50 70 0.714 24 2415 0.01 864 4.624\n",
      "PAN16 gr problem014 35 70 0.5 52 2415 0.022 898 4.603\n",
      "PAN16 gr problem015 62 70 0.886 9 2415 0.004 887 4.603\n",
      "PAN16 gr problem016 51 70 0.729 24 2415 0.01 550 4.236\n",
      "PAN16 gr problem017 64 70 0.914 7 2415 0.003 542 4.229\n",
      "PAN16 gr problem018 37 70 0.529 44 2415 0.018 672 4.262\n"
     ]
    }
   ],
   "source": [
    "print(\"Name, Language, authors, texts, r, true_links, links, true_links_ratio, mean_length\")\n",
    "id, x, y = oxquarry.parse()\n",
    "print(\"Oxquarry EN\", *dataset_infos(x, y))\n",
    "id, x_lemma, x, y = brunet.parse()\n",
    "print(\"Brunet FR\", *dataset_infos(x, y))\n",
    "id, x_pos, x_lemma, x, y = st_jean.parse()\n",
    "print(\"St-Jean FR\", *dataset_infos(x, y))\n",
    "print(\"St-Jean A 001-100 FR\", *dataset_infos(x[:100], y[:100]))\n",
    "print(\"St-Jean B 101-200 FR\", *dataset_infos(x[100:], y[100:]))\n",
    "\n",
    "\n",
    "problems = pan16.parse_train()\n",
    "for (info, _, x, y) in problems:\n",
    "    print(f\"PAN16 {info['language']} {info['folder']}\", *dataset_infos(x, y))\n",
    "problems = pan16.parse_test()\n",
    "for (info, _, x, y) in problems:\n",
    "    print(f\"PAN16 {info['language']} {info['folder']}\", *dataset_infos(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retained text representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr9(X_token, X_pos):\n",
    "    return [\n",
    "        [X_token, 0, 750, True, 1e-1, distances.cosine_distance],\n",
    "        [X_token, 0, 750, False, 1e-1, distances.clark],\n",
    "        [X_token, 0, 750, True, 1e-1, distances.manhattan],\n",
    "        [X_token, 0, 750, False, 1e-1, distances.tanimoto],\n",
    "        [X_token, 3, 3000, True, 1e-1, distances.cosine_distance],\n",
    "        [X_token, 4, 8000, True, 1e-1, distances.cosine_distance],\n",
    "        [X_pos, 2, 250, True, 1e-1, distances.cosine_distance],\n",
    "        [X_pos, 3, 1000, True, 1e-1, distances.cosine_distance],\n",
    "        (X_token, compressions.bz2, distances.cbc)\n",
    "    ]\n",
    "\n",
    "\n",
    "def tr7(X_token):\n",
    "    return [\n",
    "        [X_token, 0, 750, True, 1e-1, distances.cosine_distance],\n",
    "        [X_token, 0, 750, False, 1e-1, distances.clark],\n",
    "        [X_token, 0, 750, True, 1e-1, distances.manhattan],\n",
    "        [X_token, 0, 750, False, 1e-1, distances.tanimoto],\n",
    "        [X_token, 3, 3000, True, 1e-1, distances.cosine_distance],\n",
    "        [X_token, 4, 8000, True, 1e-1, distances.cosine_distance],\n",
    "        (X_token, compressions.bz2, distances.cbc)\n",
    "    ]\n",
    "\n",
    "\n",
    "def tr(*X):\n",
    "    if len(X) == 2:\n",
    "        return tr9(X[0], X[1])\n",
    "    else:\n",
    "        return tr7(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89  0.79 92.00]\n",
      " [ 0.89  0.80 88.00]\n",
      " [ 0.67  0.56 39.00]\n",
      " [ 0.63  0.57 54.00]\n",
      " [ 0.77  0.68 61.00]\n",
      " [ 0.78  0.68 84.00]\n",
      " [ 0.79  0.69 74.00]]\n"
     ]
    }
   ],
   "source": [
    "rls_oxquarry = [compute_links(t) for t in tr(X_token_oxquarry)]\n",
    "print(np.array([evaluate_linking(rl, Y_oxquarry) for rl in rls_oxquarry]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72  0.64 19.00]\n",
      " [ 0.71  0.67  8.00]\n",
      " [ 0.68  0.62 19.00]\n",
      " [ 0.67  0.64 22.00]\n",
      " [ 0.73  0.67 24.00]\n",
      " [ 0.74  0.67 20.00]\n",
      " [ 0.76  0.70 25.00]]\n"
     ]
    }
   ],
   "source": [
    "rls_brunet = [compute_links(t) for t in tr(X_token_brunet)]\n",
    "print(np.array([evaluate_linking(rl, Y_brunet) for rl in rls_brunet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.78  0.69 65.00]\n",
      " [ 0.75  0.66 68.00]\n",
      " [ 0.77  0.70 99.00]\n",
      " [ 0.76  0.69 80.00]\n",
      " [ 0.71  0.61 75.00]\n",
      " [ 0.76  0.65 72.00]\n",
      " [ 0.68  0.63 20.00]\n",
      " [ 0.69  0.63 18.00]\n",
      " [ 0.73  0.63 83.00]]\n"
     ]
    }
   ],
   "source": [
    "rls_st_jean_A = [compute_links(t) for t in tr(X_token_st_jean_A, X_pos_st_jean_A)]\n",
    "print(np.array([evaluate_linking(rl, Y_st_jean_A) for rl in rls_st_jean_A]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.94   0.87 165.00]\n",
      " [  0.91   0.81 124.00]\n",
      " [  0.93   0.86 156.00]\n",
      " [  0.89   0.82 169.00]\n",
      " [  0.91   0.83 172.00]\n",
      " [  0.92   0.86 182.00]\n",
      " [  0.91   0.83 132.00]\n",
      " [  0.89   0.81  80.00]\n",
      " [  0.87   0.77 153.00]]\n"
     ]
    }
   ],
   "source": [
    "rls_st_jean_B = [compute_links(t) for t in tr(X_token_st_jean_B, X_pos_st_jean_B)]\n",
    "print(np.array([evaluate_linking(rl, Y_st_jean_B) for rl in rls_st_jean_B]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.78   0.70 253.00]\n",
      " [  0.74   0.66 175.00]\n",
      " [  0.76   0.70 203.00]\n",
      " [  0.75   0.69 204.00]\n",
      " [  0.74   0.64 231.00]\n",
      " [  0.78   0.68 251.00]\n",
      " [  0.73   0.65  60.00]\n",
      " [  0.71   0.63  45.00]\n",
      " [  0.70   0.62 219.00]]\n"
     ]
    }
   ],
   "source": [
    "rls_st_jean = [compute_links(t) for t in tr(X_token_st_jean, X_pos_st_jean)]\n",
    "print(np.array([evaluate_linking(rl, Y_st_jean) for rl in rls_st_jean]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance over rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank_list = compute_links([X_token_brunet, 0, 500, False, 0.1, distances.manhattan])\n",
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "plt.plot(range(len(rank_list)), [r[-1] for r in rank_list])\n",
    "plt.xlabel(\"Rank\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/distance_over_rank.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 500\n",
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "\n",
    "min_ = 1e-10\n",
    "max_ = 20\n",
    "zoom_factors = np.arange(min_, max_, 0.06)\n",
    "\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\n",
    "    \"color\", plt.cm.hsv(np.linspace(0, 1, len(zoom_factors))))\n",
    "\n",
    "for i in zoom_factors:\n",
    "    x, y = s_curves.sigmoid_reciprocal(c=i, r=0.5)(scale)\n",
    "    plt.plot(x, y, linewidth=0.2)\n",
    "\n",
    "cbar = plt.colorbar(plt.cm.ScalarMappable(\n",
    "    norm=colors.Normalize(min_, max_), cmap=\"hsv\"))\n",
    "cbar.set_label(\"c\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/s_curve_c.png\")\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = plt.rcParamsDefault['axes.prop_cycle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 500\n",
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "\n",
    "min_ = 0.1\n",
    "max_ = 0.9\n",
    "rs = np.arange(min_, max_, 0.001)\n",
    "\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\n",
    "    \"color\", plt.cm.hsv(np.linspace(0, 1, len(rs))))\n",
    "\n",
    "for ri in rs:\n",
    "    x, y = s_curves.sigmoid_reciprocal(r=ri)(scale)\n",
    "    plt.plot(x, y, linewidth=0.2)\n",
    "\n",
    "cbar = plt.colorbar(plt.cm.ScalarMappable(\n",
    "    norm=colors.Normalize(min_, max_), cmap=\"hsv\"))\n",
    "cbar.set_label(\"r\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/s_curve_r.png\")\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = plt.rcParamsDefault['axes.prop_cycle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = []\n",
    "\n",
    "sizes = np.arange(9000, 0, -250, dtype=int)\n",
    "\n",
    "for i in sizes:\n",
    "    # limitate the data size\n",
    "    Xi = [x[:i] for x in X_token_st_jean]\n",
    "    rl = compute_links([Xi, 0, 500, True, 0.1, distances.cosine_distance])\n",
    "    m = evaluate_linking(rl, Y_st_jean)\n",
    "    print(i, m)\n",
    "    M.append(m)\n",
    "\n",
    "M = np.array(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 4), dpi=200)\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(sizes, M[:, 0], c=\"C0\", ls=\"solid\",\n",
    "         label=\"Average Precision (AP)\")\n",
    "ax1.plot(sizes, M[:, 1], c=\"C0\", ls=\"dashed\", label=\"RPrec\")\n",
    "ax2.plot(sizes, M[:, 2], c=\"C0\", ls=\"dotted\", label=\"HPRec\")\n",
    "ax1.set_xlabel(\"#Tokens per texts\")\n",
    "plt.gca().invert_xaxis()\n",
    "ax1.set_ylabel(\"AP/RPrec\")\n",
    "ax2.set_ylabel(\"HPrec\")\n",
    "plt.xticks(np.arange(9000, -1, -1000, dtype=int))\n",
    "fig.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/degradation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token and Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lemma, X_token, Y = X_lemma_st_jean, X_token_st_jean, Y_st_jean\n",
    "# X_lemma, X_token, Y = X_lemma_brunet, X_token_brunet, Y_brunet\n",
    "\n",
    "M_token = []\n",
    "M_lemma = []\n",
    "\n",
    "mfws = np.arange(100, 2000 + 1, 100)\n",
    "distances_ = distances.vector_distances\n",
    "\n",
    "for mfw in mfws:\n",
    "    print(mfw)\n",
    "    for zscore, distance in distances_:\n",
    "        rl_token = compute_links([X_token, 0, mfw, zscore, 1e-1, distance])\n",
    "        Mi = evaluate_linking(rl_token, Y)\n",
    "        M_token.append(Mi)\n",
    "\n",
    "        rl_lemma = compute_links([X_lemma, 0, mfw, zscore, 1e-1, distance])\n",
    "        Mi = evaluate_linking(rl_lemma, Y)\n",
    "        M_lemma.append(Mi)\n",
    "\n",
    "M_token = np.array(M_token).reshape(-1, len(distances_), 3)\n",
    "M_lemma = np.array(M_lemma).reshape(-1, len(distances_), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lines = [\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dotted\"),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dashed\"),\n",
    "] + [Line2D([0], [0], color=f\"C{i}\", lw=2) for i in range(len(distances_))]\n",
    "labels = [\"Token\", \"Lemma\"] + [d.__name__ for z, d in distances_]\n",
    "\n",
    "plt.figure(figsize=(6, 8), dpi=200)\n",
    "for i in range(len(distances_)):\n",
    "    plt.plot(mfws, M_token[:, i, 0], ls=\"dashed\", c=f\"C{i}\")\n",
    "    plt.plot(mfws, M_lemma[:, i, 0], ls=\"dotted\", c=f\"C{i}\")\n",
    "plt.xlabel(\"#MFW\")\n",
    "plt.ylabel(\"Average Precision (AP)\")\n",
    "plt.legend(custom_lines, labels, loc=\"lower center\", ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig(\"img/token_vs_lemma.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letters n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = X_token_oxquarry, Y_oxquarry\n",
    "# X, Y = X_token_brunet, Y_brunet\n",
    "X, Y = X_token_st_jean, Y_st_jean\n",
    "\n",
    "M = defaultdict(list)\n",
    "\n",
    "mfws = np.arange(500, 15000 + 1, 500)\n",
    "\n",
    "ngrams_types = [3, 4, 5, (2, 3), (3, 4), (4, 5)]\n",
    "for ngrams_type in ngrams_types:\n",
    "    print(ngrams_type)\n",
    "    for mfw in mfws:\n",
    "        rep = [X, ngrams_type, mfw, True, 1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M[ngrams_type].append(m)\n",
    "        print(mfw, m)\n",
    "\n",
    "M = dict(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "for ngrams_type in ngrams_types:\n",
    "    X = mfws\n",
    "    Y = [i[0] for i in M[ngrams_type]]\n",
    "    plt.plot(X, Y, label=f\"Letters {str(ngrams_type)}-grams\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"MFW\")\n",
    "plt.ylabel(\"Average Precision (AP)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/letter_ngrams.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letters n-grams 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = X_token_oxquarry, Y_oxquarry\n",
    "# X, Y = X_token_brunet, Y_brunet\n",
    "X, Y = X_token_st_jean, Y_st_jean\n",
    "\n",
    "configurations = [\n",
    "    (3, 3000),\n",
    "    (4, 8000),\n",
    "]\n",
    "\n",
    "for n_grams_type, mfw in configurations:\n",
    "    for zscore, distance in distances.vector_distances:\n",
    "        rep = [X, n_grams_type, mfw, zscore, 1e-1, distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        print(n_grams_type, mfw, distance.__name__, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, last letters, n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = X_token_oxquarry, Y_oxquarry\n",
    "# X, Y = X_token_brunet, Y_brunet\n",
    "X, Y = X_token_st_jean, Y_st_jean\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "\n",
    "for n, c in zip([3, 4, 5], [\"C0\", \"C1\", \"C2\"]):\n",
    "    print(n)\n",
    "    word_begin_X = first_letters_cut(X, n)\n",
    "    word_ngrams_X = word_n_grams(X, n)\n",
    "    word_end_X = last_letters_cut(X, n)\n",
    "\n",
    "    M_ngrams = []\n",
    "    M_first = []\n",
    "    M_last = []\n",
    "\n",
    "    mfws = np.arange(200, 4000 + 1, 100)\n",
    "\n",
    "    for mfw in mfws:\n",
    "        print(mfw)\n",
    "        rep = [word_ngrams_X, 0, mfw, True,\n",
    "               1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M_ngrams.append(m[0])\n",
    "        rep = [word_begin_X, 0, mfw, True, 1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M_first.append(m[0])\n",
    "        rep = [word_end_X, 0, mfw, True, 1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M_last.append(m[0])\n",
    "\n",
    "    plt.plot(mfws, M_ngrams, c=c, ls=\"solid\")\n",
    "    plt.plot(mfws, M_first, c=c, ls=\"dotted\")\n",
    "    plt.plot(mfws, M_last, c=c, ls=\"dashed\")\n",
    "\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], color=\"C0\", lw=2),\n",
    "    Line2D([0], [0], color=\"C1\", lw=2),\n",
    "    Line2D([0], [0], color=\"C2\", lw=2),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"solid\"),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dotted\"),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dashed\"),\n",
    "]\n",
    "\n",
    "plt.legend(custom_lines, [\"n = 3\", \"n = 4\", \"n = 5\", \"word n-grams\",\n",
    "                          \"n first letters\", \"n last letters\"], loc=\"lower right\")\n",
    "plt.xlabel(\"MFW\")\n",
    "plt.ylabel(\"Average Precision (AP)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/first_last_letters_ngrams.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = X_pos_st_jean, Y_st_jean\n",
    "\n",
    "M = defaultdict(list)\n",
    "\n",
    "mfws = np.arange(100, 2000 + 1, 100)\n",
    "\n",
    "ngrams_types = [2, 3, 4, (2, 3)]\n",
    "for ngrams_type in ngrams_types:\n",
    "    for mfw in mfws:\n",
    "        rep = [X, ngrams_type, mfw, True, 1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M[ngrams_type].append(m)\n",
    "        print(mfw, m)\n",
    "\n",
    "M = dict(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "for ngrams_type in ngrams_types:\n",
    "    X = mfws\n",
    "    Y = [i[0] for i in M[ngrams_type]]\n",
    "    plt.plot(X, Y, label=f\"POS {str(ngrams_type)}-grams\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"MFW\")\n",
    "plt.ylabel(\"Average Precision (AP)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/pos_ngrams.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS n-grams 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = X_pos_st_jean, Y_st_jean\n",
    "\n",
    "M = defaultdict(list)\n",
    "\n",
    "configurations = [\n",
    "    (2, 250),\n",
    "    (3, 1000),\n",
    "]\n",
    "\n",
    "for ngrams_type, mfw in configurations:\n",
    "    for zscore, distance in distances.vector_distances:\n",
    "        rep = [X, ngrams_type, mfw, zscore, 1e-1, distance]\n",
    "        rl = compute_links(rep)\n",
    "        print(ngrams_type, mfw, distance.__name__, evaluate_linking(rl, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = X_token_oxquarry, Y_oxquarry\n",
    "X, Y = X_token_brunet, Y_brunet\n",
    "# X, Y = X_token_st_jean, Y_st_jean\n",
    "\n",
    "compression_methods = [\n",
    "    compressions.lzma,\n",
    "    compressions.bz2,\n",
    "    compressions.gzip,\n",
    "]\n",
    "distance_funcs = [\n",
    "    distances.ncd,\n",
    "    distances.cbc,\n",
    "]\n",
    "distances_compressions = list(itertools.product(\n",
    "    compression_methods, distance_funcs))\n",
    "\n",
    "M = []\n",
    "T = []\n",
    "\n",
    "for i in range(3):\n",
    "    for compression_method, distance_func in distances_compressions:\n",
    "        print(compression_method.__name__, distance_func.__name__)\n",
    "        t0 = time.time()\n",
    "        rep = (X, compression_method, distance_func)\n",
    "        rl = compute_links(rep)\n",
    "        t = time.time() - t0\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M.append(m)\n",
    "        T.append(t)\n",
    "        print(m, t)\n",
    "\n",
    "M = np.array(M).reshape(-1, len(distances_compressions), 3)\n",
    "T = np.array(T).reshape(-1, len(distances_compressions))\n",
    "M = M.mean(axis=0)\n",
    "T = T.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)\n",
    "print(T)\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "x, y, c = M[:, 1], M[:, 0], M[:, 2]\n",
    "plt.scatter(x, y, c=c, marker=\".\")\n",
    "texts = []\n",
    "for i, (compression_method, distance_func) in enumerate(distances_compressions):\n",
    "    text = f\"({compression_method.__name__}, {distance_func.__name__})\"\n",
    "    xy = (x[i], y[i])\n",
    "    texts.append(plt.annotate(text, xy))\n",
    "adjust_text(texts)\n",
    "cbar = plt.colorbar()\n",
    "plt.xlabel(\"RPrec\")\n",
    "plt.ylabel(\"Average precision (AP)\")\n",
    "cbar.set_label(\"HPrec\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/compression_evaluation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos, X_token, Y = X_pos_st_jean, X_token_st_jean, Y_st_jean\n",
    "\n",
    "trs = tr(X_token, X_pos)\n",
    "\n",
    "top_n = 30\n",
    "keep = 2\n",
    "\n",
    "incorrectly_ranked = defaultdict(lambda: 0)\n",
    "\n",
    "rls = []\n",
    "\n",
    "for t in trs:\n",
    "    rl = compute_links(t)\n",
    "    rls.append(rl)\n",
    "    m = evaluate_linking(rl, Y)\n",
    "    print(m)\n",
    "    i = 0\n",
    "    for (a, b), s in rl:\n",
    "        if Y[a] != Y[b]:\n",
    "            i += 1\n",
    "            incorrectly_ranked[(a, b)] += 1\n",
    "            if i > top_n:\n",
    "                break\n",
    "\n",
    "rl = fusion_z_score(rls)\n",
    "m = evaluate_linking(rl, Y)\n",
    "print(m, \"(overall)\")\n",
    "top_errors = Counter(dict(incorrectly_ranked)).most_common(keep)\n",
    "print(top_errors)\n",
    "\n",
    "features, mfw = most_frequent_word(X_token, 750, lidstone_lambda=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(a, b, filename):\n",
    "    A, B = features[a, :], features[b, :]\n",
    "    mean = np.mean(np.array([A, B]), axis=0)\n",
    "    order_indices = np.argsort(mean)[::-1]\n",
    "    A = A[order_indices]\n",
    "    B = B[order_indices]\n",
    "    plt.figure(figsize=(4, 3), dpi=200)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.bar(range(len(A)), A, width=1, label=f\"{Y[a]} ({a+1})\", alpha=0.5)\n",
    "    plt.bar(range(len(A)), B, width=1, label=f\"{Y[b]} ({b+1})\", alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.xticks([], [])\n",
    "    plt.xlabel(\"MFW Vector\")\n",
    "    plt.ylabel(\"Relative word frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "(a, b), score = rl[0]\n",
    "plot(a, b, f\"img/mfw_vector_first_rl.png\")\n",
    "\n",
    "(a, b), score = rl[int(m[-1] - 1)]\n",
    "plot(a, b, f\"img/mfw_vector_first_last_rl.png\")\n",
    "\n",
    "for i, ((a, b), errors) in enumerate(top_errors):\n",
    "    plot(a, b, f\"img/mfw_vector_error_{i}.png\")\n",
    "\n",
    "(a, b), score = rl[-1]\n",
    "plot(a, b, f\"img/mfw_vector_last_rl.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info, X_pos, X_token, Y = info_st_jean, X_pos_st_jean, X_token_st_jean, Y_st_jean\n",
    "\n",
    "s = 5\n",
    "\n",
    "dates = [int(i[-1]) for i in info]\n",
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "plt.hist(dates, bins=np.arange(\n",
    "    np.min(dates), np.max(dates), s), density=True, alpha=0.7)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/dates_distribution.png\")\n",
    "\n",
    "trs = tr(X_token, X_pos)\n",
    "\n",
    "rls = []\n",
    "for t in trs:\n",
    "    rl = compute_links(t)\n",
    "    rls.append(rl)\n",
    "    print(evaluate_linking(rl, Y))\n",
    "rl = fusion_z_score(rls)\n",
    "print(evaluate_linking(rl, Y))\n",
    "\n",
    "date_diffs = np.array([np.abs(dates[a] - dates[b]) for (a, b), s in rl])\n",
    "\n",
    "correct = np.array([Y[a] == Y[b] for (a, b), s in rl])\n",
    "\n",
    "r = compute_r(Y)\n",
    "all_links = date_diffs\n",
    "true_links = date_diffs[correct]\n",
    "top_r_true_links = true_links[0:r]\n",
    "false_links = date_diffs[~correct]\n",
    "top_r_false_links = false_links[0:r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, title, color, filename):\n",
    "    plt.figure(figsize=(4, 3), dpi=200)\n",
    "    n, bins, patches = plt.hist(data, bins=np.arange(\n",
    "        0, np.max(data), s), color=color, alpha=0.7, density=True, label=\"Distibution\")\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    plt.axvline(mean, c=color, linestyle=\"dashed\",\n",
    "                label=f\"Mean = {mean:.2f}\")\n",
    "    plt.hlines(y=n.max() / 2 - n.min() / 2, xmin=mean - std // 2, xmax=mean +\n",
    "               std // 2, color=color, linestyle=\"solid\", label=f\"Std = {std:.2f}\")\n",
    "    h, l = plt.gca().get_legend_handles_labels()\n",
    "    order = [1, 0, 2]\n",
    "    plt.legend([h[i] for i in order], [l[i] for i in order])\n",
    "    plt.xlabel(\"Date difference\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.tight_layout()\n",
    "    xticks = np.arange(date_diffs.min(), date_diffs.max(), 10)\n",
    "    plt.xticks(xticks)\n",
    "    plt.savefig(filename)\n",
    "\n",
    "plot(all_links, \"All links\", \"C0\", \"img/dates_differences_all.png\")\n",
    "plot(false_links, \"false links\", \"C1\", \"img/dates_differences_false.png\")\n",
    "plot(top_r_true_links, \"top-r true links, true links\", \"C2\",\n",
    "     \"img/dates_differences_r_true.png\")\n",
    "plot(top_r_false_links, \"top-r false links\", \"C3\",\n",
    "     \"img/dates_differences_r_false.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, Y_training = (X_token_st_jean_A, X_pos_st_jean_A), Y_st_jean_A\n",
    "X_testing, Y_testing = (X_token_st_jean_B, X_pos_st_jean_B), Y_st_jean_B\n",
    "\n",
    "# X_training, Y_training = (X_token_st_jean_B, X_pos_st_jean_B), Y_st_jean_B\n",
    "# X_testing, Y_testing = (X_token_st_jean_A, X_pos_st_jean_A), Y_st_jean_A\n",
    "\n",
    "fusion_size = 4\n",
    "\n",
    "models = []\n",
    "print(\"Training rank lists\")\n",
    "tr_training = tr9(*X_training)[0:5]\n",
    "for i, t in enumerate(tr_training):\n",
    "    rl = compute_links(t)\n",
    "    model, rmse = fusion_regression_training(rl, Y_training)\n",
    "    models.append(model)\n",
    "    mesures = evaluate_linking(rl, Y_training)\n",
    "    print(i, *mesures, rmse)\n",
    "\n",
    "M_single = []\n",
    "rank_lists = []\n",
    "print(\"Testing rank lists\")\n",
    "tr_testing = tr9(*X_testing)[0:5]\n",
    "for i, t in enumerate(tr_testing):\n",
    "    rl = compute_links(t)\n",
    "    rank_lists.append(rl)\n",
    "    mesures = evaluate_linking(rl, Y_testing)\n",
    "    M_single.append(mesures)\n",
    "    print(i, *mesures)\n",
    "\n",
    "M_single = np.array(M_single)\n",
    "\n",
    "M_single_max = []\n",
    "M_single_mean = []\n",
    "M_fusion_z_score = []\n",
    "M_fusion_regression = []\n",
    "\n",
    "tr_ids = np.array(\n",
    "    list(itertools.combinations(range(len(tr_training)), fusion_size)))\n",
    "\n",
    "for tr_id in tr_ids:\n",
    "    rls = [rank_lists[i] for i in tr_id]\n",
    "\n",
    "    m_single_max = np.max(M_single[tr_id, :], axis=0)\n",
    "    M_single_max.append(m_single_max)\n",
    "\n",
    "    m_single_mean = np.mean(M_single[tr_id, :], axis=0)\n",
    "    M_single_mean.append(m_single_mean)\n",
    "\n",
    "    rl_z_score = fusion_z_score(rls)\n",
    "    m_z_score = evaluate_linking(rl_z_score, Y_testing)\n",
    "    M_fusion_z_score.append(m_z_score)\n",
    "\n",
    "    rl_regression = fusion_regression(models, rls)\n",
    "    m_regression = evaluate_linking(rl_regression, Y_testing)\n",
    "    M_fusion_regression.append(m_regression)\n",
    "\n",
    "M_single_max = np.array(M_single_max)\n",
    "M_single_mean = np.array(M_single_mean)\n",
    "M_fusion_z_score = np.array(M_fusion_z_score)\n",
    "M_fusion_regression = np.array(M_fusion_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "x, y, c = M_single[:, 1], M_single[:, 0], M_single[:, 2]\n",
    "plt.scatter(x, y, c=c, marker=\"o\", label=\"Single rank list\", alpha=0.8)\n",
    "x, y, c = M_fusion_regression[:,\n",
    "                              1], M_fusion_regression[:, 0], M_fusion_regression[:, 2]\n",
    "plt.scatter(x, y, c=c, marker=\"x\",\n",
    "            label=f\"Regression fusions ({fusion_size} lists)\", alpha=0.5)\n",
    "x, y, c = M_fusion_z_score[:,\n",
    "                           1], M_fusion_z_score[:, 0], M_fusion_z_score[:, 2]\n",
    "plt.scatter(x, y, c=c, marker=\"+\",\n",
    "            label=f\"Z-score fusions ({fusion_size} lists)\", alpha=0.5)\n",
    "cbar = plt.colorbar()\n",
    "plt.xlabel(\"RPrec\")\n",
    "plt.ylabel(\"Average precision (AP)\")\n",
    "cbar.set_label(\"HPrec\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/fusion_evaluation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fusion Statistics\")\n",
    "\n",
    "def print_statistics_latex(M_list):\n",
    "    print(\"Min &\", \" & \".join(\n",
    "        np.round(M_list.min(axis=0), 3).astype(str)), r\"\\\\\")\n",
    "    mean_std = zip(np.round(M_list.mean(axis=0), 3).astype(\n",
    "        str), np.round(M_list.std(axis=0), 3).astype(str))\n",
    "    mean_std = [f\"{mean}\\pm{std}\" for mean, std in mean_std]\n",
    "    print(\"Mean$\\pm$Std &\", \" & \".join(mean_std), r\"\\\\\")\n",
    "    print(\"Max &\", \" & \".join(\n",
    "        np.round(M_list.max(axis=0), 3).astype(str)), r\"\\\\\")\n",
    "    argmin = tr_ids[np.argmin(M_list, axis=0)]\n",
    "    print(\"Argmin &\", \" & \".join(\n",
    "        [np.array2string(a, separator=\",\") for a in argmin]), r\"\\\\\")\n",
    "    argmax = tr_ids[np.argmax(M_list, axis=0)]\n",
    "    print(\"Argmax &\", \" & \".join(\n",
    "        [np.array2string(a, separator=\",\") for a in argmax]), r\"\\\\\")\n",
    "\n",
    "print(\"Single mean\")\n",
    "print_statistics_latex(M_single_mean)\n",
    "print(\"Single max\")\n",
    "print_statistics_latex(M_single_max)\n",
    "print(\"Z-score\")\n",
    "print_statistics_latex(M_fusion_z_score)\n",
    "print(\"Regression\")\n",
    "print_statistics_latex(M_fusion_regression)\n",
    "\n",
    "print(\"Fusion sign tests\")\n",
    "print(\"Z-score/T/Single-mean\")\n",
    "print(*sign_test(M_fusion_z_score, M_single_mean))\n",
    "print(\"Z-score/T/Single-max\")\n",
    "print(*sign_test(M_fusion_z_score, M_single_max))\n",
    "print(\"Regression/T/Single-mean\")\n",
    "print(*sign_test(M_fusion_regression, M_single_mean))\n",
    "print(\"Regression/T/Single-max\")\n",
    "print(*sign_test(M_fusion_regression, M_single_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veto fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linking(X, Y):\n",
    "    rls = [compute_links(t) for t in tr(*X)]\n",
    "    for rl in rls:\n",
    "        print(evaluate_linking(rl, Y))\n",
    "    return rls\n",
    "\n",
    "def _method(threshold, value):\n",
    "    def f(scores):\n",
    "        scores[scores < threshold] = value\n",
    "        return scores\n",
    "    return f\n",
    "\n",
    "def _veto_fusions(rls_training, rls_testing, Y_training, Y_testing, value):\n",
    "    models = [fusion_regression_training(\n",
    "        rl, Y_training)[0] for rl in rls_training]\n",
    "    rl_no_veto = fusion_regression(models, rls_testing)\n",
    "    baseline = evaluate_linking(rl_no_veto, Y_testing)[0]\n",
    "    y = []\n",
    "    for xi in x:\n",
    "        rl_veto = fusion_regression(\n",
    "            models, rls_testing, alter_scores=_method(xi, value))\n",
    "        m = evaluate_linking(rl_veto, Y_testing)\n",
    "        y.append(m[0])\n",
    "    y = np.array(y) - baseline\n",
    "    return y\n",
    "\n",
    "def _plot(value, c):\n",
    "    print(value)\n",
    "    y = _veto_fusions(rls_A, rls_B, Y_A, Y_B, value)\n",
    "    print(\"A B\", np.max(y), x[np.argmax(y)])\n",
    "    plt.plot(x, y, label=\"train A, test B\", ls=\"dotted\", c=c, alpha=0.5)\n",
    "    y = _veto_fusions(rls_B, rls_A, Y_B, Y_A, value)\n",
    "    print(\"B A\", np.max(y), x[np.argmax(y)])\n",
    "    plt.plot(x, y, label=\"train B, test A\", ls=\"dashed\", c=c, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_A, X_token_A, Y_A = X_pos_st_jean_A, X_token_st_jean_A, Y_st_jean_A\n",
    "X_pos_B, X_token_B, Y_B = X_pos_st_jean_B, X_token_st_jean_B, Y_st_jean_B\n",
    "\n",
    "print(\"A\")\n",
    "rls_A = _linking((X_token_A, X_pos_A), Y_A)\n",
    "print(\"B\")\n",
    "rls_B = _linking((X_token_B, X_pos_B), Y_B)\n",
    "\n",
    "x = np.linspace(0.01, 0.25, 25)\n",
    "values = [0, -1, -len(rls_A), -np.inf]\n",
    "\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dotted\"),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dashed\"),\n",
    "] + [Line2D([0], [0], color=f\"C{i}\", lw=2) for i in range(len(values))]\n",
    "labels = [\"Train A / Test B\", \"Train B / Test A\"] + \\\n",
    "    [f\"Set {str(v)}\" for v in values]\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "for i, value in enumerate(values):\n",
    "    _plot(value, f\"C{str(i)}\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"AP diff.\")\n",
    "plt.legend(custom_lines, labels)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/veto.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion with soft veto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = (X_oxquarry,), Y_oxquarry\n",
    "# X, Y = (X_brunet,), Y_brunet\n",
    "# X, Y = (X_token_st_jean_A, X_token_st_jean_A), Y_st_jean_A\n",
    "# X, Y = (X_token_st_jean_B, X_token_st_jean_B), Y_st_jean_B\n",
    "\n",
    "rls = []\n",
    "tr_ = tr(*X)\n",
    "\n",
    "print(\"linking\")\n",
    "for i, t in enumerate(tr_):\n",
    "    rl = compute_links(t)\n",
    "    mesures = evaluate_linking(rl, Y)\n",
    "    print(i, *mesures)\n",
    "    rls.append(rl)\n",
    "\n",
    "print(\"vanilla\")\n",
    "rl = fusion_z_score(rls)\n",
    "M_vanilla = evaluate_linking(rl, Y)[0]\n",
    "\n",
    "print(\"soft veto\")\n",
    "resolution = 25\n",
    "cs = np.linspace(0, 0.1, resolution)\n",
    "rs = np.linspace(0, 0.3, resolution)\n",
    "print(cs)\n",
    "print(rs)\n",
    "c_r = np.array(list(itertools.product(cs, rs)))\n",
    "M_softveto = []\n",
    "for a, b in c_r:\n",
    "    s_curve = s_curves.full_boost(top=a, bottom=b)\n",
    "    # s_curve = s_curves.sigmoid_reciprocal(c=a, r=b)\n",
    "    rls_veto = [s_curves.soft_veto(rl, s_curve) for rl in rls]\n",
    "    rl = fusion_z_score(rls_veto)\n",
    "    M_softveto.append(evaluate_linking(rl, Y)[0])\n",
    "\n",
    "M_softveto = np.array(M_softveto).reshape((resolution, -1))\n",
    "M_softveto -= M_vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax = np.max(np.abs([np.min(M_softveto), np.max(M_softveto)]))\n",
    "\n",
    "print(np.max(M_softveto))\n",
    "print(c_r[np.argmax(M_softveto)])\n",
    "\n",
    "plt.scatter(x=c_r[:, 0], y=c_r[:, 1],\n",
    "            c=M_softveto, cmap=\"RdYlGn\", marker=\"s\",\n",
    "            vmin=-vmax, vmax=vmax\n",
    "            )\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"top\")\n",
    "plt.ylabel(\"bottom\")\n",
    "plt.xticks(np.linspace(np.min(cs), np.max(cs), 6))\n",
    "plt.yticks(np.linspace(np.min(rs), np.max(rs), 6))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/soft_veto_heat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Score fusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ([X_token_oxquarry, ], Y_oxquarry),\n",
    "    ([X_token_brunet, ], Y_brunet),\n",
    "    ([X_token_st_jean_A, X_pos_st_jean_A], Y_st_jean_A),\n",
    "    ([X_token_st_jean_B, X_pos_st_jean_B], Y_st_jean_B),\n",
    "]\n",
    "\n",
    "for Xs, Ys in datasets:\n",
    "    tr_ = tr(*Xs)\n",
    "    rls = []\n",
    "    for i in tr_:\n",
    "        rl = compute_links(i)\n",
    "        print(evaluate_linking(rl, Ys))\n",
    "        rls.append(rl)\n",
    "    rl = fusion_z_score(rls)\n",
    "    print(evaluate_linking(rl, Ys), \"(overall)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank list correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ nan 0.32 0.04 0.77 0.64 0.77 0.86 0.92 0.08]\n",
      " [0.32  nan 0.35 0.85 0.30 0.42 0.68 0.58 0.34]\n",
      " [0.04 0.35  nan 0.07 0.03 0.09 0.22 0.12 0.21]\n",
      " [0.77 0.85 0.07  nan 0.22 0.50 0.38 0.50 0.12]\n",
      " [0.64 0.30 0.03 0.22  nan 0.71 0.48 0.63 0.00]\n",
      " [0.77 0.42 0.09 0.50 0.71  nan 0.70 0.93 0.01]\n",
      " [0.86 0.68 0.22 0.38 0.48 0.70  nan 0.63 0.19]\n",
      " [0.92 0.58 0.12 0.50 0.63 0.93 0.63  nan 0.15]\n",
      " [0.08 0.34 0.21 0.12 0.00 0.01 0.19 0.15  nan]]\n",
      "-0.03671380082868155 0.07691385575887037 -0.34810152757249263 0.03748274213066229 0.016956462041636065\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2a5737959c4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mslope\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mXs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mYs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwilcoxon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_method_rank_list(rls):\n",
    "    s = len(rls)\n",
    "    ids = range(s)\n",
    "    d = []\n",
    "    for Ai, Bi in itertools.product(ids, ids):\n",
    "        A, B = rls[Ai], rls[Bi]\n",
    "        dist = rank_list_distance(A, B)\n",
    "        d.append(dist)\n",
    "    d = np.array(d).reshape((s, s))\n",
    "    return d\n",
    "\n",
    "def get_ranks(d, rls, Y, aggregation):\n",
    "    gain, wilcoxon = [], []\n",
    "    for ids in itertools.combinations(range(d.shape[0]), 2):\n",
    "        fusion_rl = [rls[id] for id in ids]\n",
    "        \n",
    "        m_single_rls = [evaluate_linking(rl, Y) for rl in fusion_rl]\n",
    "        m_single = aggregation(m_single_rls, axis=0)\n",
    "        m_fuse = evaluate_linking(fusion_z_score(fusion_rl), Y)\n",
    "        diff = m_fuse - m_single\n",
    "        \n",
    "        gain.append(diff[0])\n",
    "        wilcoxon.append(d[ids])\n",
    "        \n",
    "    return np.array(wilcoxon), np.array(gain)\n",
    "\n",
    "rls = rls_st_jean_A\n",
    "Y = Y_st_jean_A\n",
    "\n",
    "d = compute_method_rank_list(rls)\n",
    "print(d)\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "plt.figure(figsize=(6,4), dpi=200)\n",
    "\n",
    "for aggregation in [np.mean, np.max]:\n",
    "    wilcoxon, gain = get_ranks(d, rls, Y, aggregation)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(wilcoxon, gain)\n",
    "    print(slope, intercept, r_value, p_value, std_err)\n",
    "\n",
    "    def f(x):\n",
    "        return slope * x + intercept\n",
    "    Xs = np.array([0, 1])\n",
    "    Ys = f(X)\n",
    "    plt.scatter(wilcoxon, gain, label=aggregation.__name__)\n",
    "    plt.plot(Xs, Ys)\n",
    "plt.legend()\n",
    "plt.xlabel(\"wilcoxon p-value\")\n",
    "plt.ylabel(\"AP gain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, X, Y = oxquarry.parse()\n",
    "_, _, X, Y = brunet.parse()\n",
    "# _, X_pos, _, X_token, Y = st_jean.parse_A()\n",
    "# _, X_pos, _, X_token, Y = st_jean.parse_B()\n",
    "\n",
    "# tr = tr9(X_token, X_pos)\n",
    "tr = tr7(X)\n",
    "\n",
    "ips_stop = 0.1\n",
    "\n",
    "print(\"AP RPrec HPrec\")\n",
    "rank_lists = [compute_links(t) for t in tr]\n",
    "for rank_list in rank_lists:\n",
    "    print(evaluate_linking(rank_list, Y))\n",
    "\n",
    "print(\"Overall\")\n",
    "rank_list_overall = fusion_z_score(rank_lists)\n",
    "print(evaluate_linking(rank_list_overall, Y))\n",
    "\n",
    "labels, silhouette_scores = unsupervised_clustering(\n",
    "    rank_list_overall, ips_stop=ips_stop, return_scores=True)\n",
    "\n",
    "print(\"bcubed.precision\", \"bcubed.recall\", \"bcubed.fscore\", \"r ratio diff\")\n",
    "print(evaluate_clustering(Y, labels))\n",
    "\n",
    "ns, labels_list = clustering_at_every_n_clusters(rank_list_overall)\n",
    "evaluations = np.array([evaluate_clustering(Y, labels)\n",
    "                        for labels in labels_list])\n",
    "\n",
    "n_clusters_found = len(np.unique(labels))\n",
    "n_clusters_actual = len(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "plt.plot(ns, evaluations[:, 0], label=\"BCubed $F_1$ Score\")\n",
    "plt.plot(ns, evaluations[:, 1], label=\"BCubed Precision\")\n",
    "plt.plot(ns, evaluations[:, 2], label=\"BCubed Recall\")\n",
    "plt.plot(ns, evaluations[:, 3], label=\"r ratio diff\")\n",
    "plt.plot(*silhouette_scores, label=\"Silhouette Score\")\n",
    "plt.axvline(n_clusters_found, 0, 1,\n",
    "            ls=\"dashed\", c=\"C4\", label=\"IPS Procedure #Clusters\")\n",
    "plt.axvline(n_clusters_actual, 0, 1,\n",
    "            ls=\"dashed\", c=\"C2\", label=\"Actual #Clusters\")\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "ypos = ymax / 2 - ymin / 2\n",
    "plt.text(n_clusters_found, ypos,\n",
    "         f\"{n_clusters_found}\", c=\"C4\", rotation=\"vertical\")\n",
    "plt.text(n_clusters_actual, ypos,\n",
    "         f\"{n_clusters_actual}\", c=\"C2\", rotation=\"vertical\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"#Clusters\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/unsupervised_clustering.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(rl, Y, n_clusters_found, n_clusters_actual, filename):\n",
    "    ns, labels_list = clustering_at_every_n_clusters(rl)\n",
    "    evaluations = np.array([evaluate_clustering(Y, labels)\n",
    "                            for labels in labels_list])\n",
    "\n",
    "    plt.figure(figsize=(6, 4), dpi=200)\n",
    "    plt.plot(ns, evaluations[:, 0], label=\"BCubed Precision\")\n",
    "    plt.plot(ns, evaluations[:, 1], label=\"BCubed Recall\")\n",
    "    plt.plot(ns, evaluations[:, 2], label=\"BCubed $F_1$ Score\")\n",
    "    plt.axvline(n_clusters_found, 0, 1,\n",
    "                ls=\"dashed\", c=\"C3\", label=\"LogisticRegression #Clusters\")\n",
    "    plt.axvline(n_clusters_actual, 0, 1,\n",
    "                ls=\"dashed\", c=\"C2\", label=\"Actual #Clusters\")\n",
    "    xmin, xmax, ymin, ymax = plt.axis()\n",
    "    ypos = ymax / 2 - ymin / 2\n",
    "    plt.text(n_clusters_found, ypos,\n",
    "             f\"{n_clusters_found}\", c=\"C3\", rotation=\"vertical\")\n",
    "    plt.text(n_clusters_actual, ypos,\n",
    "             f\"{n_clusters_actual}\", c=\"C2\", rotation=\"vertical\")\n",
    "    plt.grid()\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"#Clusters\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"img/{filename}.png\")\n",
    "\n",
    "datasets = [\n",
    "    ([X_token_oxquarry, ], Y_oxquarry),\n",
    "    ([X_token_brunet, ], Y_brunet),\n",
    "    ([X_token_st_jean_A, X_pos_st_jean_A], Y_st_jean_A),\n",
    "    ([X_token_st_jean_B, X_pos_st_jean_B], Y_st_jean_B),\n",
    "]\n",
    "\n",
    "dataset_labels = [\n",
    "    \"oxquarry\",\n",
    "    \"brunet\",\n",
    "    \"st_jean_a\",\n",
    "    \"st_jean_b\",\n",
    "]\n",
    "ids = range(len(datasets))\n",
    "\n",
    "dataset_rls = []\n",
    "\n",
    "print(\"Computing rank lists\")\n",
    "for id in ids:\n",
    "    X, Y = datasets[id]\n",
    "    tr_training = tr(*X)\n",
    "    rls = [compute_links(t) for t in tr_training]\n",
    "    for rl in rls:\n",
    "        M = evaluate_linking(rl, Y)\n",
    "        print(M)\n",
    "    rl = fusion_z_score(rls)\n",
    "    dataset_rls.append(rl)\n",
    "    print(dataset_labels[id], evaluate_linking(rl, Y))\n",
    "\n",
    "m = []\n",
    "print(\"Supervised clustering\")\n",
    "for A, B in itertools.product(ids, ids):\n",
    "    X_training, Y_training = datasets[A]\n",
    "    rl_training = dataset_rls[A]\n",
    "    X_testing, Y_testing = datasets[B]\n",
    "    rl_testing = dataset_rls[B]\n",
    "\n",
    "    model = supervised_clustering_training(rl_training, Y_training)\n",
    "    Y_pred = supervised_clustering_predict(model, rl_testing)\n",
    "\n",
    "    M = evaluate_clustering(Y_testing, Y_pred)\n",
    "    m.append(M)\n",
    "    print(dataset_labels[A], dataset_labels[B], M)\n",
    "\n",
    "print(np.array(m).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
