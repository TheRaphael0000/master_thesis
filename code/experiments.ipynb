{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std Python Lib\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "# Requirements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import wilcoxon\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Project\n",
    "import distances\n",
    "import compressions\n",
    "import s_curves\n",
    "\n",
    "from corpus import brunet\n",
    "from corpus import oxquarry\n",
    "from corpus import st_jean\n",
    "from corpus import pan16\n",
    "\n",
    "from rank_list_fusion import fusion_z_score\n",
    "from rank_list_fusion import fusion_regression_training\n",
    "from rank_list_fusion import fusion_regression\n",
    "\n",
    "from evaluate import evaluate_linking\n",
    "from evaluate import evaluate_clustering\n",
    "\n",
    "from linking import compute_links\n",
    "from linking import most_frequent_word\n",
    "\n",
    "from clustering import supervised_clustering_training\n",
    "from clustering import supervised_clustering_predict\n",
    "from clustering import unsupervised_clustering\n",
    "from clustering import clustering_at_every_n_clusters\n",
    "\n",
    "from misc import sign_test\n",
    "from misc import first_letters_cut\n",
    "from misc import word_n_grams\n",
    "from misc import last_letters_cut\n",
    "from misc import sigmoid\n",
    "from misc import sigmoid_r\n",
    "from misc import compute_r\n",
    "from misc import normalize\n",
    "from misc import rank_list_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Oxquarry\")\n",
    "info_oxquarry, X_token_oxquarry, Y_oxquarry = oxquarry.parse()\n",
    "print(\"Loading Brunet\")\n",
    "info_brunet, X_lemma_brunet, X_token_brunet, Y_brunet = brunet.parse()\n",
    "print(\"Loading St-Jean A\")\n",
    "info_st_jean_A, X_pos_st_jean_A, X_lemma_st_jean_A, X_token_st_jean_A, Y_st_jean_A = st_jean.parse_A()\n",
    "print(\"Loading St-Jean B\")\n",
    "info_st_jean_B, X_pos_st_jean_B, X_lemma_st_jean_B, X_token_st_jean_B, Y_st_jean_B = st_jean.parse_B()\n",
    "print(\"Loading St-Jean\")\n",
    "info_st_jean, X_pos_st_jean, X_lemma_st_jean, X_token_st_jean, Y_st_jean = st_jean.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retained text representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr9(X_token, X_pos):\n",
    "    return [\n",
    "        [X_token, 0, 750, True, 1e-1, distances.cosine_distance],\n",
    "        [X_token, 0, 750, False, 1e-1, distances.clark],\n",
    "        [X_token, 0, 750, True, 1e-1, distances.manhattan],\n",
    "        [X_token, 0, 750, False, 1e-1, distances.tanimoto],\n",
    "        [X_token, 3, 3000, True, 1e-1, distances.cosine_distance],\n",
    "        [X_token, 4, 8000, True, 1e-1, distances.cosine_distance],\n",
    "        [X_pos, 2, 250, True, 1e-1, distances.cosine_distance],\n",
    "        [X_pos, 3, 1000, True, 1e-1, distances.cosine_distance],\n",
    "        (X_token, compressions.bz2, distances.cbc)\n",
    "    ]\n",
    "\n",
    "\n",
    "def tr7(X_token):\n",
    "    return [\n",
    "        [X_token, 0, 750, True, 1e-1, distances.cosine_distance],\n",
    "        [X_token, 0, 750, False, 1e-1, distances.clark],\n",
    "        [X_token, 0, 750, True, 1e-1, distances.manhattan],\n",
    "        [X_token, 0, 750, False, 1e-1, distances.tanimoto],\n",
    "        [X_token, 3, 3000, True, 1e-1, distances.cosine_distance],\n",
    "        [X_token, 4, 8000, True, 1e-1, distances.cosine_distance],\n",
    "        (X_token, compressions.bz2, distances.cbc)\n",
    "    ]\n",
    "\n",
    "\n",
    "def tr(*X):\n",
    "    if len(X) == 2:\n",
    "        return tr9(X[0], X[1])\n",
    "    else:\n",
    "        return tr7(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rls_oxquarry = [compute_links(t) for t in tr(X_token_oxquarry)]\n",
    "print(np.array([evaluate_linking(rl, Y_oxquarry) for rl in rls_oxquarry]))\n",
    "\n",
    "rls_brunet = [compute_links(t) for t in tr(X_token_brunet)]\n",
    "print(np.array([evaluate_linking(rl, Y_brunet) for rl in rls_brunet]))\n",
    "\n",
    "rls_st_jean_A = [compute_links(t) for t in tr(X_token_st_jean_A, X_pos_st_jean_A)]\n",
    "print(np.array([evaluate_linking(rl, Y_st_jean_A) for rl in rls_st_jean_A]))\n",
    "\n",
    "rls_st_jean_B = [compute_links(t) for t in tr(X_token_st_jean_B, X_pos_st_jean_B)]\n",
    "print(np.array([evaluate_linking(rl, Y_st_jean_B) for rl in rls_st_jean_B]))\n",
    "\n",
    "#rls_st_jean = [compute_links(t) for t in tr(X_token_st_jean, X_pos_st_jean)]\n",
    "#print(np.array([evaluate_linking(rl, Y_st_jean) for rl in rls_st_jean]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distance_over_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list = compute_links([X_token_brunet, 0, 500, False, 0.1, distances.manhattan])\n",
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "plt.plot(range(len(rank_list)), [r[-1] for r in rank_list])\n",
    "plt.xlabel(\"Rank\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/distance_over_rank.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## s_curve_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 500\n",
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "\n",
    "min_ = 1e-10\n",
    "max_ = 20\n",
    "zoom_factors = np.arange(min_, max_, 0.06)\n",
    "\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\n",
    "    \"color\", plt.cm.hsv(np.linspace(0, 1, len(zoom_factors))))\n",
    "\n",
    "for i in zoom_factors:\n",
    "    x, y = s_curves.sigmoid_reciprocal(c=i, r=0.5)(scale)\n",
    "    plt.plot(x, y, linewidth=0.2)\n",
    "\n",
    "cbar = plt.colorbar(plt.cm.ScalarMappable(\n",
    "    norm=colors.Normalize(min_, max_), cmap=\"hsv\"))\n",
    "cbar.set_label(\"c\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/s_curve_c.png\")\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = plt.rcParamsDefault['axes.prop_cycle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## s_curve_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 500\n",
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "\n",
    "min_ = 0.1\n",
    "max_ = 0.9\n",
    "rs = np.arange(min_, max_, 0.001)\n",
    "\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\n",
    "    \"color\", plt.cm.hsv(np.linspace(0, 1, len(rs))))\n",
    "\n",
    "for ri in rs:\n",
    "    x, y = s_curves.sigmoid_reciprocal(r=ri)(scale)\n",
    "    plt.plot(x, y, linewidth=0.2)\n",
    "\n",
    "cbar = plt.colorbar(plt.cm.ScalarMappable(\n",
    "    norm=colors.Normalize(min_, max_), cmap=\"hsv\"))\n",
    "cbar.set_label(\"r\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/s_curve_r.png\")\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = plt.rcParamsDefault['axes.prop_cycle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = []\n",
    "\n",
    "sizes = np.arange(9000, 0, -250, dtype=int)\n",
    "\n",
    "for i in sizes:\n",
    "    # limitate the data size\n",
    "    Xi = [x[:i] for x in X_token_st_jean]\n",
    "    rl = compute_links([Xi, 0, 500, True, 0.1, distances.cosine_distance])\n",
    "    m = evaluate_linking(rl, Y_st_jean)\n",
    "    print(i, m)\n",
    "    M.append(m)\n",
    "\n",
    "M = np.array(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 4), dpi=200)\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(sizes, M[:, 0], c=\"C0\", ls=\"solid\",\n",
    "         label=\"Average Precision (AP)\")\n",
    "ax1.plot(sizes, M[:, 1], c=\"C0\", ls=\"dashed\", label=\"RPrec\")\n",
    "ax2.plot(sizes, M[:, 2], c=\"C0\", ls=\"dotted\", label=\"HPRec\")\n",
    "ax1.set_xlabel(\"#Tokens per texts\")\n",
    "plt.gca().invert_xaxis()\n",
    "ax1.set_ylabel(\"AP/RPrec\")\n",
    "ax2.set_ylabel(\"HPrec\")\n",
    "plt.xticks(np.arange(9000, -1, -1000, dtype=int))\n",
    "fig.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/degradation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token_vs_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lemma, X_token, Y = X_lemma_st_jean, X_token_st_jean, Y_st_jean\n",
    "# X_lemma, X_token, Y = X_lemma_brunet, X_token_brunet, Y_brunet\n",
    "\n",
    "M_token = []\n",
    "M_lemma = []\n",
    "\n",
    "mfws = np.arange(100, 2000 + 1, 100)\n",
    "distances_ = distances.vector_distances\n",
    "\n",
    "for mfw in mfws:\n",
    "    print(mfw)\n",
    "    for zscore, distance in distances_:\n",
    "        rl_token = compute_links([X_token, 0, mfw, zscore, 1e-1, distance])\n",
    "        Mi = evaluate_linking(rl_token, Y)\n",
    "        M_token.append(Mi)\n",
    "\n",
    "        rl_lemma = compute_links([X_lemma, 0, mfw, zscore, 1e-1, distance])\n",
    "        Mi = evaluate_linking(rl_lemma, Y)\n",
    "        M_lemma.append(Mi)\n",
    "\n",
    "M_token = np.array(M_token).reshape(-1, len(distances_), 3)\n",
    "M_lemma = np.array(M_lemma).reshape(-1, len(distances_), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lines = [\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dotted\"),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dashed\"),\n",
    "] + [Line2D([0], [0], color=f\"C{i}\", lw=2) for i in range(len(distances_))]\n",
    "labels = [\"Token\", \"Lemma\"] + [d.__name__ for z, d in distances_]\n",
    "\n",
    "plt.figure(figsize=(6, 8), dpi=200)\n",
    "for i in range(len(distances_)):\n",
    "    plt.plot(mfws, M_token[:, i, 0], ls=\"dashed\", c=f\"C{i}\")\n",
    "    plt.plot(mfws, M_lemma[:, i, 0], ls=\"dotted\", c=f\"C{i}\")\n",
    "plt.xlabel(\"#MFW\")\n",
    "plt.ylabel(\"Average Precision (AP)\")\n",
    "plt.legend(custom_lines, labels, loc=\"lower center\", ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig(\"img/token_vs_lemma.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## letter_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = X_token_oxquarry, Y_oxquarry\n",
    "# X, Y = X_token_brunet, Y_brunet\n",
    "X, Y = X_token_st_jean, Y_st_jean\n",
    "\n",
    "M = defaultdict(list)\n",
    "\n",
    "mfws = np.arange(500, 15000 + 1, 500)\n",
    "\n",
    "ngrams_types = [3, 4, 5, (2, 3), (3, 4), (4, 5)]\n",
    "for ngrams_type in ngrams_types:\n",
    "    print(ngrams_type)\n",
    "    for mfw in mfws:\n",
    "        rep = [X, ngrams_type, mfw, True, 1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M[ngrams_type].append(m)\n",
    "        print(mfw, m)\n",
    "\n",
    "M = dict(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "for ngrams_type in ngrams_types:\n",
    "    X = mfws\n",
    "    Y = [i[0] for i in M[ngrams_type]]\n",
    "    plt.plot(X, Y, label=f\"Letters {str(ngrams_type)}-grams\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"MFW\")\n",
    "plt.ylabel(\"Average Precision (AP)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/letter_ngrams.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## letter_ngrams_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = X_token_oxquarry, Y_oxquarry\n",
    "# X, Y = X_token_brunet, Y_brunet\n",
    "X, Y = X_token_st_jean, Y_st_jean\n",
    "\n",
    "configurations = [\n",
    "    (3, 3000),\n",
    "    (4, 8000),\n",
    "]\n",
    "\n",
    "for n_grams_type, mfw in configurations:\n",
    "    for zscore, distance in distances.vector_distances:\n",
    "        rep = [X, n_grams_type, mfw, zscore, 1e-1, distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        print(n_grams_type, mfw, distance.__name__, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first_last_letters_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = X_token_oxquarry, Y_oxquarry\n",
    "# X, Y = X_token_brunet, Y_brunet\n",
    "X, Y = X_token_st_jean, Y_st_jean\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "\n",
    "for n, c in zip([3, 4, 5], [\"C0\", \"C1\", \"C2\"]):\n",
    "    print(n)\n",
    "    word_begin_X = first_letters_cut(X, n)\n",
    "    word_ngrams_X = word_n_grams(X, n)\n",
    "    word_end_X = last_letters_cut(X, n)\n",
    "\n",
    "    M_ngrams = []\n",
    "    M_first = []\n",
    "    M_last = []\n",
    "\n",
    "    mfws = np.arange(200, 4000 + 1, 100)\n",
    "\n",
    "    for mfw in mfws:\n",
    "        print(mfw)\n",
    "        rep = [word_ngrams_X, 0, mfw, True,\n",
    "               1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M_ngrams.append(m[0])\n",
    "        rep = [word_begin_X, 0, mfw, True, 1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M_first.append(m[0])\n",
    "        rep = [word_end_X, 0, mfw, True, 1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M_last.append(m[0])\n",
    "\n",
    "    plt.plot(mfws, M_ngrams, c=c, ls=\"solid\")\n",
    "    plt.plot(mfws, M_first, c=c, ls=\"dotted\")\n",
    "    plt.plot(mfws, M_last, c=c, ls=\"dashed\")\n",
    "\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], color=\"C0\", lw=2),\n",
    "    Line2D([0], [0], color=\"C1\", lw=2),\n",
    "    Line2D([0], [0], color=\"C2\", lw=2),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"solid\"),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dotted\"),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dashed\"),\n",
    "]\n",
    "\n",
    "plt.legend(custom_lines, [\"n = 3\", \"n = 4\", \"n = 5\", \"word n-grams\",\n",
    "                          \"n first letters\", \"n last letters\"], loc=\"lower right\")\n",
    "plt.xlabel(\"MFW\")\n",
    "plt.ylabel(\"Average Precision (AP)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/first_last_letters_ngrams.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pos_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = X_pos_st_jean, Y_st_jean\n",
    "\n",
    "M = defaultdict(list)\n",
    "\n",
    "mfws = np.arange(100, 2000 + 1, 100)\n",
    "\n",
    "ngrams_types = [2, 3, 4, (2, 3)]\n",
    "for ngrams_type in ngrams_types:\n",
    "    for mfw in mfws:\n",
    "        rep = [X, ngrams_type, mfw, True, 1e-1, distances.cosine_distance]\n",
    "        rl = compute_links(rep)\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M[ngrams_type].append(m)\n",
    "        print(mfw, m)\n",
    "\n",
    "M = dict(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "for ngrams_type in ngrams_types:\n",
    "    X = mfws\n",
    "    Y = [i[0] for i in M[ngrams_type]]\n",
    "    plt.plot(X, Y, label=f\"POS {str(ngrams_type)}-grams\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"MFW\")\n",
    "plt.ylabel(\"Average Precision (AP)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/pos_ngrams.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pos_ngrams_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = X_pos_st_jean, Y_st_jean\n",
    "\n",
    "M = defaultdict(list)\n",
    "\n",
    "configurations = [\n",
    "    (2, 250),\n",
    "    (3, 1000),\n",
    "]\n",
    "\n",
    "for ngrams_type, mfw in configurations:\n",
    "    for zscore, distance in distances.vector_distances:\n",
    "        rep = [X, ngrams_type, mfw, zscore, 1e-1, distance]\n",
    "        rl = compute_links(rep)\n",
    "        print(ngrams_type, mfw, distance.__name__, evaluate_linking(rl, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compression_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = X_token_oxquarry, Y_oxquarry\n",
    "X, Y = X_token_brunet, Y_brunet\n",
    "# X, Y = X_token_st_jean, Y_st_jean\n",
    "\n",
    "compression_methods = [\n",
    "    compressions.lzma,\n",
    "    compressions.bz2,\n",
    "    compressions.gzip,\n",
    "]\n",
    "distance_funcs = [\n",
    "    distances.ncd,\n",
    "    distances.cbc,\n",
    "]\n",
    "distances_compressions = list(itertools.product(\n",
    "    compression_methods, distance_funcs))\n",
    "\n",
    "M = []\n",
    "T = []\n",
    "\n",
    "for i in range(3):\n",
    "    for compression_method, distance_func in distances_compressions:\n",
    "        print(compression_method.__name__, distance_func.__name__)\n",
    "        t0 = time.time()\n",
    "        rep = (X, compression_method, distance_func)\n",
    "        rl = compute_links(rep)\n",
    "        t = time.time() - t0\n",
    "        m = evaluate_linking(rl, Y)\n",
    "        M.append(m)\n",
    "        T.append(t)\n",
    "        print(m, t)\n",
    "\n",
    "M = np.array(M).reshape(-1, len(distances_compressions), 3)\n",
    "T = np.array(T).reshape(-1, len(distances_compressions))\n",
    "M = M.mean(axis=0)\n",
    "T = T.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)\n",
    "print(T)\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "x, y, c = M[:, 1], M[:, 0], M[:, 2]\n",
    "plt.scatter(x, y, c=c, marker=\".\")\n",
    "texts = []\n",
    "for i, (compression_method, distance_func) in enumerate(distances_compressions):\n",
    "    text = f\"({compression_method.__name__}, {distance_func.__name__})\"\n",
    "    xy = (x[i], y[i])\n",
    "    texts.append(plt.annotate(text, xy))\n",
    "adjust_text(texts)\n",
    "cbar = plt.colorbar()\n",
    "plt.xlabel(\"RPrec\")\n",
    "plt.ylabel(\"Average precision (AP)\")\n",
    "cbar.set_label(\"HPrec\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/compression_evaluation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frequent_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos, X_token, Y = X_pos_st_jean, X_token_st_jean, Y_st_jean\n",
    "\n",
    "trs = tr(X_token, X_pos)\n",
    "\n",
    "top_n = 30\n",
    "keep = 2\n",
    "\n",
    "incorrectly_ranked = defaultdict(lambda: 0)\n",
    "\n",
    "rls = []\n",
    "\n",
    "for t in trs:\n",
    "    rl = compute_links(t)\n",
    "    rls.append(rl)\n",
    "    m = evaluate_linking(rl, Y)\n",
    "    print(m)\n",
    "    i = 0\n",
    "    for (a, b), s in rl:\n",
    "        if Y[a] != Y[b]:\n",
    "            i += 1\n",
    "            incorrectly_ranked[(a, b)] += 1\n",
    "            if i > top_n:\n",
    "                break\n",
    "\n",
    "rl = fusion_z_score(rls)\n",
    "m = evaluate_linking(rl, Y)\n",
    "print(m, \"(overall)\")\n",
    "top_errors = Counter(dict(incorrectly_ranked)).most_common(keep)\n",
    "print(top_errors)\n",
    "\n",
    "features, mfw = most_frequent_word(X_token, 750, lidstone_lambda=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(a, b, filename):\n",
    "    A, B = features[a, :], features[b, :]\n",
    "    mean = np.mean(np.array([A, B]), axis=0)\n",
    "    order_indices = np.argsort(mean)[::-1]\n",
    "    A = A[order_indices]\n",
    "    B = B[order_indices]\n",
    "    plt.figure(figsize=(4, 3), dpi=200)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.bar(range(len(A)), A, width=1, label=f\"{Y[a]} ({a+1})\", alpha=0.5)\n",
    "    plt.bar(range(len(A)), B, width=1, label=f\"{Y[b]} ({b+1})\", alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.xticks([], [])\n",
    "    plt.xlabel(\"MFW Vector\")\n",
    "    plt.ylabel(\"Relative word frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "(a, b), score = rl[0]\n",
    "plot(a, b, f\"img/mfw_vector_first_rl.png\")\n",
    "\n",
    "(a, b), score = rl[int(m[-1] - 1)]\n",
    "plot(a, b, f\"img/mfw_vector_first_last_rl.png\")\n",
    "\n",
    "for i, ((a, b), errors) in enumerate(top_errors):\n",
    "    plot(a, b, f\"img/mfw_vector_error_{i}.png\")\n",
    "\n",
    "(a, b), score = rl[-1]\n",
    "plot(a, b, f\"img/mfw_vector_last_rl.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## date_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info, X_pos, X_token, Y = info_st_jean, X_pos_st_jean, X_token_st_jean, Y_st_jean\n",
    "\n",
    "s = 5\n",
    "\n",
    "dates = [int(i[-1]) for i in info]\n",
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "plt.hist(dates, bins=np.arange(\n",
    "    np.min(dates), np.max(dates), s), density=True, alpha=0.7)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/dates_distribution.png\")\n",
    "\n",
    "trs = tr(X_token, X_pos)\n",
    "\n",
    "rls = []\n",
    "for t in trs:\n",
    "    rl = compute_links(t)\n",
    "    rls.append(rl)\n",
    "    print(evaluate_linking(rl, Y))\n",
    "rl = fusion_z_score(rls)\n",
    "print(evaluate_linking(rl, Y))\n",
    "\n",
    "date_diffs = np.array([np.abs(dates[a] - dates[b]) for (a, b), s in rl])\n",
    "\n",
    "correct = np.array([Y[a] == Y[b] for (a, b), s in rl])\n",
    "\n",
    "r = compute_r(Y)\n",
    "all_links = date_diffs\n",
    "true_links = date_diffs[correct]\n",
    "top_r_true_links = true_links[0:r]\n",
    "false_links = date_diffs[~correct]\n",
    "top_r_false_links = false_links[0:r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, title, color, filename):\n",
    "    plt.figure(figsize=(4, 3), dpi=200)\n",
    "    n, bins, patches = plt.hist(data, bins=np.arange(\n",
    "        0, np.max(data), s), color=color, alpha=0.7, density=True, label=\"Distibution\")\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    plt.axvline(mean, c=color, linestyle=\"dashed\",\n",
    "                label=f\"Mean = {mean:.2f}\")\n",
    "    plt.hlines(y=n.max() / 2 - n.min() / 2, xmin=mean - std // 2, xmax=mean +\n",
    "               std // 2, color=color, linestyle=\"solid\", label=f\"Std = {std:.2f}\")\n",
    "    h, l = plt.gca().get_legend_handles_labels()\n",
    "    order = [1, 0, 2]\n",
    "    plt.legend([h[i] for i in order], [l[i] for i in order])\n",
    "    plt.xlabel(\"Date difference\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.tight_layout()\n",
    "    xticks = np.arange(date_diffs.min(), date_diffs.max(), 10)\n",
    "    plt.xticks(xticks)\n",
    "    plt.savefig(filename)\n",
    "\n",
    "plot(all_links, \"All links\", \"C0\", \"img/dates_differences_all.png\")\n",
    "plot(false_links, \"false links\", \"C1\", \"img/dates_differences_false.png\")\n",
    "plot(top_r_true_links, \"top-r true links, true links\", \"C2\",\n",
    "     \"img/dates_differences_r_true.png\")\n",
    "plot(top_r_false_links, \"top-r false links\", \"C3\",\n",
    "     \"img/dates_differences_r_false.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fusion_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, Y_training = (X_token_st_jean_A, X_pos_st_jean_A), Y_st_jean_A\n",
    "X_testing, Y_testing = (X_token_st_jean_B, X_pos_st_jean_B), Y_st_jean_B\n",
    "\n",
    "# X_training, Y_training = (X_token_st_jean_B, X_pos_st_jean_B), Y_st_jean_B\n",
    "# X_testing, Y_testing = (X_token_st_jean_A, X_pos_st_jean_A), Y_st_jean_A\n",
    "\n",
    "fusion_size = 4\n",
    "\n",
    "models = []\n",
    "print(\"Training rank lists\")\n",
    "tr_training = tr9(*X_training)[0:5]\n",
    "for i, t in enumerate(tr_training):\n",
    "    rl = compute_links(t)\n",
    "    model, rmse = fusion_regression_training(rl, Y_training)\n",
    "    models.append(model)\n",
    "    mesures = evaluate_linking(rl, Y_training)\n",
    "    print(i, *mesures, rmse)\n",
    "\n",
    "M_single = []\n",
    "rank_lists = []\n",
    "print(\"Testing rank lists\")\n",
    "tr_testing = tr9(*X_testing)[0:5]\n",
    "for i, t in enumerate(tr_testing):\n",
    "    rl = compute_links(t)\n",
    "    rank_lists.append(rl)\n",
    "    mesures = evaluate_linking(rl, Y_testing)\n",
    "    M_single.append(mesures)\n",
    "    print(i, *mesures)\n",
    "\n",
    "M_single = np.array(M_single)\n",
    "\n",
    "M_single_max = []\n",
    "M_single_mean = []\n",
    "M_fusion_z_score = []\n",
    "M_fusion_regression = []\n",
    "\n",
    "tr_ids = np.array(\n",
    "    list(itertools.combinations(range(len(tr_training)), fusion_size)))\n",
    "\n",
    "for tr_id in tr_ids:\n",
    "    rls = [rank_lists[i] for i in tr_id]\n",
    "\n",
    "    m_single_max = np.max(M_single[tr_id, :], axis=0)\n",
    "    M_single_max.append(m_single_max)\n",
    "\n",
    "    m_single_mean = np.mean(M_single[tr_id, :], axis=0)\n",
    "    M_single_mean.append(m_single_mean)\n",
    "\n",
    "    rl_z_score = fusion_z_score(rls)\n",
    "    m_z_score = evaluate_linking(rl_z_score, Y_testing)\n",
    "    M_fusion_z_score.append(m_z_score)\n",
    "\n",
    "    rl_regression = fusion_regression(models, rls)\n",
    "    m_regression = evaluate_linking(rl_regression, Y_testing)\n",
    "    M_fusion_regression.append(m_regression)\n",
    "\n",
    "M_single_max = np.array(M_single_max)\n",
    "M_single_mean = np.array(M_single_mean)\n",
    "M_fusion_z_score = np.array(M_fusion_z_score)\n",
    "M_fusion_regression = np.array(M_fusion_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "x, y, c = M_single[:, 1], M_single[:, 0], M_single[:, 2]\n",
    "plt.scatter(x, y, c=c, marker=\"o\", label=\"Single rank list\", alpha=0.8)\n",
    "x, y, c = M_fusion_regression[:,\n",
    "                              1], M_fusion_regression[:, 0], M_fusion_regression[:, 2]\n",
    "plt.scatter(x, y, c=c, marker=\"x\",\n",
    "            label=f\"Regression fusions ({fusion_size} lists)\", alpha=0.5)\n",
    "x, y, c = M_fusion_z_score[:,\n",
    "                           1], M_fusion_z_score[:, 0], M_fusion_z_score[:, 2]\n",
    "plt.scatter(x, y, c=c, marker=\"+\",\n",
    "            label=f\"Z-score fusions ({fusion_size} lists)\", alpha=0.5)\n",
    "cbar = plt.colorbar()\n",
    "plt.xlabel(\"RPrec\")\n",
    "plt.ylabel(\"Average precision (AP)\")\n",
    "cbar.set_label(\"HPrec\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/fusion_evaluation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fusion Statistics\")\n",
    "\n",
    "def print_statistics_latex(M_list):\n",
    "    print(\"Min &\", \" & \".join(\n",
    "        np.round(M_list.min(axis=0), 3).astype(str)), r\"\\\\\")\n",
    "    mean_std = zip(np.round(M_list.mean(axis=0), 3).astype(\n",
    "        str), np.round(M_list.std(axis=0), 3).astype(str))\n",
    "    mean_std = [f\"{mean}\\pm{std}\" for mean, std in mean_std]\n",
    "    print(\"Mean$\\pm$Std &\", \" & \".join(mean_std), r\"\\\\\")\n",
    "    print(\"Max &\", \" & \".join(\n",
    "        np.round(M_list.max(axis=0), 3).astype(str)), r\"\\\\\")\n",
    "    argmin = tr_ids[np.argmin(M_list, axis=0)]\n",
    "    print(\"Argmin &\", \" & \".join(\n",
    "        [np.array2string(a, separator=\",\") for a in argmin]), r\"\\\\\")\n",
    "    argmax = tr_ids[np.argmax(M_list, axis=0)]\n",
    "    print(\"Argmax &\", \" & \".join(\n",
    "        [np.array2string(a, separator=\",\") for a in argmax]), r\"\\\\\")\n",
    "\n",
    "print(\"Single mean\")\n",
    "print_statistics_latex(M_single_mean)\n",
    "print(\"Single max\")\n",
    "print_statistics_latex(M_single_max)\n",
    "print(\"Z-score\")\n",
    "print_statistics_latex(M_fusion_z_score)\n",
    "print(\"Regression\")\n",
    "print_statistics_latex(M_fusion_regression)\n",
    "\n",
    "print(\"Fusion sign tests\")\n",
    "print(\"Z-score/T/Single-mean\")\n",
    "print(*sign_test(M_fusion_z_score, M_single_mean))\n",
    "print(\"Z-score/T/Single-max\")\n",
    "print(*sign_test(M_fusion_z_score, M_single_max))\n",
    "print(\"Regression/T/Single-mean\")\n",
    "print(*sign_test(M_fusion_regression, M_single_mean))\n",
    "print(\"Regression/T/Single-max\")\n",
    "print(*sign_test(M_fusion_regression, M_single_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## veto_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linking(X, Y):\n",
    "    rls = [compute_links(t) for t in tr(*X)]\n",
    "    for rl in rls:\n",
    "        print(evaluate_linking(rl, Y))\n",
    "    return rls\n",
    "\n",
    "def _method(threshold, value):\n",
    "    def f(scores):\n",
    "        scores[scores < threshold] = value\n",
    "        return scores\n",
    "    return f\n",
    "\n",
    "def _veto_fusions(rls_training, rls_testing, Y_training, Y_testing, value):\n",
    "    models = [fusion_regression_training(\n",
    "        rl, Y_training)[0] for rl in rls_training]\n",
    "    rl_no_veto = fusion_regression(models, rls_testing)\n",
    "    baseline = evaluate_linking(rl_no_veto, Y_testing)[0]\n",
    "    y = []\n",
    "    for xi in x:\n",
    "        rl_veto = fusion_regression(\n",
    "            models, rls_testing, alter_scores=_method(xi, value))\n",
    "        m = evaluate_linking(rl_veto, Y_testing)\n",
    "        y.append(m[0])\n",
    "    y = np.array(y) - baseline\n",
    "    return y\n",
    "\n",
    "def _plot(value, c):\n",
    "    print(value)\n",
    "    y = _veto_fusions(rls_A, rls_B, Y_A, Y_B, value)\n",
    "    print(\"A B\", np.max(y), x[np.argmax(y)])\n",
    "    plt.plot(x, y, label=\"train A, test B\", ls=\"dotted\", c=c, alpha=0.5)\n",
    "    y = _veto_fusions(rls_B, rls_A, Y_B, Y_A, value)\n",
    "    print(\"B A\", np.max(y), x[np.argmax(y)])\n",
    "    plt.plot(x, y, label=\"train B, test A\", ls=\"dashed\", c=c, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_A, X_token_A, Y_A = X_pos_st_jean_A, X_token_st_jean_A, Y_st_jean_A\n",
    "X_pos_B, X_token_B, Y_B = X_pos_st_jean_B, X_token_st_jean_B, Y_st_jean_B\n",
    "\n",
    "print(\"A\")\n",
    "rls_A = _linking((X_token_A, X_pos_A), Y_A)\n",
    "print(\"B\")\n",
    "rls_B = _linking((X_token_B, X_pos_B), Y_B)\n",
    "\n",
    "x = np.linspace(0.01, 0.25, 25)\n",
    "values = [0, -1, -len(rls_A), -np.inf]\n",
    "\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dotted\"),\n",
    "    Line2D([0], [0], color=\"k\", lw=2, ls=\"dashed\"),\n",
    "] + [Line2D([0], [0], color=f\"C{i}\", lw=2) for i in range(len(values))]\n",
    "labels = [\"Train A / Test B\", \"Train B / Test A\"] + \\\n",
    "    [f\"Set {str(v)}\" for v in values]\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "for i, value in enumerate(values):\n",
    "    _plot(value, f\"C{str(i)}\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"AP diff.\")\n",
    "plt.legend(custom_lines, labels)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/veto.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fusion_with_soft_veto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = (X_oxquarry,), Y_oxquarry\n",
    "# X, Y = (X_brunet,), Y_brunet\n",
    "# X, Y = (X_token_st_jean_A, X_token_st_jean_A), Y_st_jean_A\n",
    "# X, Y = (X_token_st_jean_B, X_token_st_jean_B), Y_st_jean_B\n",
    "\n",
    "rls = []\n",
    "tr_ = tr(*X)\n",
    "\n",
    "print(\"linking\")\n",
    "for i, t in enumerate(tr_):\n",
    "    rl = compute_links(t)\n",
    "    mesures = evaluate_linking(rl, Y)\n",
    "    print(i, *mesures)\n",
    "    rls.append(rl)\n",
    "\n",
    "print(\"vanilla\")\n",
    "rl = fusion_z_score(rls)\n",
    "M_vanilla = evaluate_linking(rl, Y)[0]\n",
    "\n",
    "print(\"soft veto\")\n",
    "resolution = 25\n",
    "cs = np.linspace(0, 0.1, resolution)\n",
    "rs = np.linspace(0, 0.3, resolution)\n",
    "print(cs)\n",
    "print(rs)\n",
    "c_r = np.array(list(itertools.product(cs, rs)))\n",
    "M_softveto = []\n",
    "for a, b in c_r:\n",
    "    s_curve = s_curves.full_boost(top=a, bottom=b)\n",
    "    # s_curve = s_curves.sigmoid_reciprocal(c=a, r=b)\n",
    "    rls_veto = [s_curves.soft_veto(rl, s_curve) for rl in rls]\n",
    "    rl = fusion_z_score(rls_veto)\n",
    "    M_softveto.append(evaluate_linking(rl, Y)[0])\n",
    "\n",
    "M_softveto = np.array(M_softveto).reshape((resolution, -1))\n",
    "M_softveto -= M_vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax = np.max(np.abs([np.min(M_softveto), np.max(M_softveto)]))\n",
    "\n",
    "print(np.max(M_softveto))\n",
    "print(c_r[np.argmax(M_softveto)])\n",
    "\n",
    "plt.scatter(x=c_r[:, 0], y=c_r[:, 1],\n",
    "            c=M_softveto, cmap=\"RdYlGn\", marker=\"s\",\n",
    "            vmin=-vmax, vmax=vmax\n",
    "            )\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"top\")\n",
    "plt.ylabel(\"bottom\")\n",
    "plt.xticks(np.linspace(np.min(cs), np.max(cs), 6))\n",
    "plt.yticks(np.linspace(np.min(rs), np.max(rs), 6))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/soft_veto_heat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## every fusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ([X_token_oxquarry, ], Y_oxquarry),\n",
    "    ([X_token_brunet, ], Y_brunet),\n",
    "    ([X_token_st_jean_A, X_pos_st_jean_A], Y_st_jean_A),\n",
    "    ([X_token_st_jean_B, X_pos_st_jean_B], Y_st_jean_B),\n",
    "]\n",
    "\n",
    "for Xs, Ys in datasets:\n",
    "    tr_ = tr(*Xs)\n",
    "    rls = []\n",
    "    for i in tr_:\n",
    "        rl = compute_links(i)\n",
    "        print(evaluate_linking(rl, Ys))\n",
    "        rls.append(rl)\n",
    "    rl = fusion_z_score(rls)\n",
    "    print(evaluate_linking(rl, Ys), \"(overall)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unsupervised_clustering_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, X, Y = oxquarry.parse()\n",
    "_, _, X, Y = brunet.parse()\n",
    "# _, X_pos, _, X_token, Y = st_jean.parse_A()\n",
    "# _, X_pos, _, X_token, Y = st_jean.parse_B()\n",
    "\n",
    "# tr = tr9(X_token, X_pos)\n",
    "tr = tr7(X)\n",
    "\n",
    "ips_stop = 0.1\n",
    "\n",
    "print(\"AP RPrec HPrec\")\n",
    "rank_lists = [compute_links(t) for t in tr]\n",
    "for rank_list in rank_lists:\n",
    "    print(evaluate_linking(rank_list, Y))\n",
    "\n",
    "print(\"Overall\")\n",
    "rank_list_overall = fusion_z_score(rank_lists)\n",
    "print(evaluate_linking(rank_list_overall, Y))\n",
    "\n",
    "labels, silhouette_scores = unsupervised_clustering(\n",
    "    rank_list_overall, ips_stop=ips_stop, return_scores=True)\n",
    "\n",
    "print(\"bcubed.precision\", \"bcubed.recall\", \"bcubed.fscore\", \"r ratio diff\")\n",
    "print(evaluate_clustering(Y, labels))\n",
    "\n",
    "ns, labels_list = clustering_at_every_n_clusters(rank_list_overall)\n",
    "evaluations = np.array([evaluate_clustering(Y, labels)\n",
    "                        for labels in labels_list])\n",
    "\n",
    "n_clusters_found = len(np.unique(labels))\n",
    "n_clusters_actual = len(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=200)\n",
    "plt.plot(ns, evaluations[:, 0], label=\"BCubed $F_1$ Score\")\n",
    "plt.plot(ns, evaluations[:, 1], label=\"BCubed Precision\")\n",
    "plt.plot(ns, evaluations[:, 2], label=\"BCubed Recall\")\n",
    "plt.plot(ns, evaluations[:, 3], label=\"r ratio diff\")\n",
    "plt.plot(*silhouette_scores, label=\"Silhouette Score\")\n",
    "plt.axvline(n_clusters_found, 0, 1,\n",
    "            ls=\"dashed\", c=\"C4\", label=\"IPS Procedure #Clusters\")\n",
    "plt.axvline(n_clusters_actual, 0, 1,\n",
    "            ls=\"dashed\", c=\"C2\", label=\"Actual #Clusters\")\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "ypos = ymax / 2 - ymin / 2\n",
    "plt.text(n_clusters_found, ypos,\n",
    "         f\"{n_clusters_found}\", c=\"C4\", rotation=\"vertical\")\n",
    "plt.text(n_clusters_actual, ypos,\n",
    "         f\"{n_clusters_actual}\", c=\"C2\", rotation=\"vertical\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"#Clusters\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/unsupervised_clustering.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## supervised_clustering_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(rl, Y, n_clusters_found, n_clusters_actual, filename):\n",
    "    ns, labels_list = clustering_at_every_n_clusters(rl)\n",
    "    evaluations = np.array([evaluate_clustering(Y, labels)\n",
    "                            for labels in labels_list])\n",
    "\n",
    "    plt.figure(figsize=(6, 4), dpi=200)\n",
    "    plt.plot(ns, evaluations[:, 0], label=\"BCubed Precision\")\n",
    "    plt.plot(ns, evaluations[:, 1], label=\"BCubed Recall\")\n",
    "    plt.plot(ns, evaluations[:, 2], label=\"BCubed $F_1$ Score\")\n",
    "    plt.axvline(n_clusters_found, 0, 1,\n",
    "                ls=\"dashed\", c=\"C3\", label=\"LogisticRegression #Clusters\")\n",
    "    plt.axvline(n_clusters_actual, 0, 1,\n",
    "                ls=\"dashed\", c=\"C2\", label=\"Actual #Clusters\")\n",
    "    xmin, xmax, ymin, ymax = plt.axis()\n",
    "    ypos = ymax / 2 - ymin / 2\n",
    "    plt.text(n_clusters_found, ypos,\n",
    "             f\"{n_clusters_found}\", c=\"C3\", rotation=\"vertical\")\n",
    "    plt.text(n_clusters_actual, ypos,\n",
    "             f\"{n_clusters_actual}\", c=\"C2\", rotation=\"vertical\")\n",
    "    plt.grid()\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"#Clusters\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"img/{filename}.png\")\n",
    "\n",
    "datasets = [\n",
    "    ([X_token_oxquarry, ], Y_oxquarry),\n",
    "    ([X_token_brunet, ], Y_brunet),\n",
    "    ([X_token_st_jean_A, X_pos_st_jean_A], Y_st_jean_A),\n",
    "    ([X_token_st_jean_B, X_pos_st_jean_B], Y_st_jean_B),\n",
    "]\n",
    "\n",
    "dataset_labels = [\n",
    "    \"oxquarry\",\n",
    "    \"brunet\",\n",
    "    \"st_jean_a\",\n",
    "    \"st_jean_b\",\n",
    "]\n",
    "ids = range(len(datasets))\n",
    "\n",
    "dataset_rls = []\n",
    "\n",
    "print(\"Computing rank lists\")\n",
    "for id in ids:\n",
    "    X, Y = datasets[id]\n",
    "    tr_training = tr(*X)\n",
    "    rls = [compute_links(t) for t in tr_training]\n",
    "    for rl in rls:\n",
    "        M = evaluate_linking(rl, Y)\n",
    "        print(M)\n",
    "    rl = fusion_z_score(rls)\n",
    "    dataset_rls.append(rl)\n",
    "    print(dataset_labels[id], evaluate_linking(rl, Y))\n",
    "\n",
    "m = []\n",
    "print(\"Supervised clustering\")\n",
    "for A, B in itertools.product(ids, ids):\n",
    "    X_training, Y_training = datasets[A]\n",
    "    rl_training = dataset_rls[A]\n",
    "    X_testing, Y_testing = datasets[B]\n",
    "    rl_testing = dataset_rls[B]\n",
    "\n",
    "    model = supervised_clustering_training(rl_training, Y_training)\n",
    "    Y_pred = supervised_clustering_predict(model, rl_testing)\n",
    "\n",
    "    M = evaluate_clustering(Y_testing, Y_pred)\n",
    "    m.append(M)\n",
    "    print(dataset_labels[A], dataset_labels[B], M)\n",
    "\n",
    "print(np.array(m).mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rank_list_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rls = rls_oxquarry\n",
    "rls = rls_brunet\n",
    "# rls = rls_st_jean_A\n",
    "# rls = rls_st_jean_B\n",
    "\n",
    "s = len(rls)\n",
    "ids = range(s)\n",
    "\n",
    "d = []\n",
    "\n",
    "for Ai, Bi in itertools.product(ids, ids):\n",
    "    A, B = rls[Ai], rls[Bi]\n",
    "    dist = rank_list_dist(A, B)\n",
    "    d.append(dist)\n",
    "\n",
    "d = np.array(d).reshape((s, s))\n",
    "print(d)\n",
    "print(np.nanmean(d, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
