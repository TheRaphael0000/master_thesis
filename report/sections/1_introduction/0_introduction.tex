% The Introduction chapter contains: the problem statement (which scientific questions have to be answered), objectives (which goals have to be achieved) and Outline (which research methods are taken in account).

\section{Introduction \label{sec:introduction}}

In a world where the information starts to propagate really fast through social networks, forums or blogs and allow anonymous communication or pseudonymous communications, cyber-criminals have risen on the Internet~\cite{automated_unsupervised}~\cite{kocher_pan16}.
A wide range of crimes are available for attackers which can goes from a credit card theft to the Denial of Service (DoS) attack of a country infrastructure.
Some fake news spreading or phishing by e-mails attempts can be detected using network based systems.
Depending on the quality of the attack, these systems can be insuffisant to correctly discriminate between real e-mails and news to false ones and find the author(s) of the attack.
While committing cyber-crimes, cyber-criminals can ensure their anonymity and hide their traces by using techniques such as IP masking through proxies, DNSflux which consist into changing randomly DNS (Domain Name System) entries, spoofing email-sending address, using a fake account (for example a fake Facebook account), stealing an identity (for example the email account of an important politician), use distributed attacks (botnets) and more~\cite{attribution_in_cyberspace}.
Due to the increase of criminal using these techniques, new systems able to detect authors based solely on the text are needed~\cite{automated_unsupervised}~\cite{unine_pan20_fake_news}.

The field of stylometry consists of analyse the style of a written text.
This can be used to estimate text authorships based only on the text content.
These techniques can be used for journalists, law courts, cybersecurity and forensic investigators to give authorship clues for their work when dealing with for example ransom notes~\cite{pan16_clustering_site}.

Another problem when dealing with for example Internet crimes is a lack of real world labelled datasets, since the labels for this type of data can not be determinate accurately due to the anonymity that provide the Internet.
Developing automatic and unsupervised authorship techniques is required to solve these problems~\cite{automated_unsupervised}.
A typical unsupervised authorship problem is to find in a large corpus of texts which are written by the same author.
This problem is called authorship clustering.
An example where the authorship clustering can be useful is to be able to regroup text written by anonymous writers.
The writing anonymity can be due to: its need for cyber-criminals, terrorist organizations or due to the lost of the identity of the author for old texts.
For this study, stylometric and authorship techniques are applied to the authorship clustering problem.

\subsection{Research questions}

The two main research questions for this study are:

\begin{itemize}
  \item Using the principle of combination of evidence can the rank lists' fusion improve the quality of authorship rank lists ?
  \item Can a good authorship clustering be obtained using rank lists obtained by fusion ?
\end{itemize}

By answering the first question, this provides a simple framework that can be used in multiple fields using rank lists such as the information retrieval, recommender systems, authorship attribution, authorship clustering and most classification problems based on complete graphs.
With the second question, we aim to evaluate a possible use case for the rank list fusion by realizing an authorship clustering task with the obtained rank lists.

\subsection{Contributions}

In this study, the following contributions are made to the computer science computational linguistic scientific community:

\begin{enumerate}
  \item An evaluation of most frequent words frequency feature extraction strategy using : tokens, n-grams, POS n-grams text representation and multiple distance metrics.
  \item An brief evaluation of the compression based methods for authorship attribution.
  \item A methodology to create robust rank lists for authorship attribution and authorship clustering, using combination of evidence based on rank lists fusions.
  \item An brief evaluation of the mean Silhouette score maximization for unsupervised authorship hierarchical clustering as well as an optimization proposition for authorship clustering.
  \item A proposition and evaluation of a semi-supervised authorship clustering model based on an authorship attribution modelling using a mixture of two beta distribution and hierarchical clustering.
  \item A proposition and evaluation of a supervised authorship clustering model based on hierarchical clustering and the logistic regression.
\end{enumerate}

\subsection{Overview}

An overview of the current technique used in the authorship field is presented in Chapter~\ref{sec:state_of_the_art}.
Chapter~\ref{sec:definitions_and_corpora} show some definitions and introduce the corpora used for the evaluations part.
In Chapter~\ref{sec:methods} the methods used in the current study are described, this section encompasses methods proposed such as the rank generations, rank lists fusions and the clustering proposed methods.
The methods proposed in the previous are evaluated in Chapter~\ref{sec:evaluation} as well as the results of diverse experiments.
Finally, Chapter~\ref{sec:conclusion} conclude this paper by reviewing the experiments, results and indicate the potential clues to continue the study.

\subsection{Implementation and evaluation}

The experiments realized in this study were written in the Python programming language (version 3.8.8)~\cite{python}, using the following libraries:
\begin{itemize}
  \item Python Standard Library 3.8.8, for the data types, functional programming, file and direcotry access, data compression, text processing~\cite{python_standard_library}
  \item Matplotlib 3.3.4, for the plot generations~\cite{matplotlib}
  \item Numpy 1.20.2, for scientific computations~\cite{numpy}
  \item SciPy 1.4.1, for scientific computations~\cite{scipy}
  \item Scikit-learn 0.24.1, for machine learning algorithms implementations~\cite{sklearn}
  \item bcubed 1.5, to compute the BCubed family metrics~\cite{bcubed_gh}
  \item adjustText 0.7.3, for automatics text adjustments in plots~\cite{adjustText}
  \item tqdm 4.60.0, to have progress bars for heavy computations~\cite{tqdm}
\end{itemize}
The methods proposed are written in separate Python files (extension .py).
Instead, the experiments are contained in a special file format called IPython Notebook (extension .ipynb)~\cite{jupyter}.

In this report, each evaluation is described by its purpose in the study, the methodology used to conduct it, the results obtained in the form of: graphic, table or statistics coming from the experiments.
An analysis of the results and sometimes a few additional conclusions are also available.

A Jupyter environment is required to run these files.
For instance JupyterLab allows markdown annotation, the possibility to run only portions of codes and even new code in the same Python kernel this is in particular useful to avoid having to run heavy computation multiple times during the implementation and optimizations of the methods.
