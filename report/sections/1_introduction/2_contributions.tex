\section{Contributions}

In this study, the following contributions are made to the computer science computational linguistic scientific community:

\begin{enumerate}
  \item
  An evaluation of most frequent feature extraction strategy using : tokens, lemmas, $n$-grams, POS sequences text representation with multiple distance metrics.
  \item
  An brief evaluation of the compression-based methods for authorship attribution.
  \item
  An brief evaluation of the mean Silhouette score maximization for unsupervised hierarchical clustering in the authorship use case. Additionally, an optimization proposition for the authorship clustering use case is proposed.
  \item
  A proposition and evaluation of a supervised authorship clustering model based on an authorship attribution modelling using a mixture of two beta distribution and hierarchical clustering.
  \item
  A proposition and evaluation of a supervised authorship clustering model based on the logistic regression and the hierarchical clustering.
  \item
  A methodology to create robust rank lists for authorship attribution and authorship clustering, using rank lists' fusions based on combination of evidence.
\end{enumerate}

Even though the proposed clustering methods are optimized for the authorship clustering problem, they can also be applied to many other fields, for example:
\begin{itemize}
  \item
  Texts categorization : regrouping texts from the same categories (for examples, automatic news article categorization).
  \item
  Computer vision clustering : regrouping images/videos of the same natures.
  \item
  Scientific clustering : regrouping samples from experiments sensors.
\end{itemize}

As for the clustering methods, fusion techniques proposed in this study are also applicable to other fields, such as:
\begin{itemize}
  \item
  Media search / Search engines : Combining results from multiple information retrieval systems.
  \item
  Information filtering : Combining results from multiple recommender systems.
  \item
  Machine learning : Combining multiple results from LTR models (learning to rank models).
\end{itemize}
