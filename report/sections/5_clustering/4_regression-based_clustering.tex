\section{Regression-based clustering \label{sec:regression-based_clustering}}

\subsection{Method}

To learn at which position in the rank list the cut should be, this third idea is to fit a linear regression model on samples created from the rank list.
The model must be linear, since only one cut should separate the true links and the false links.
To train the model, a sample is created for each link in a rank list.
The links labels are either \textit{true} (1.0) when both document in the link are from the same author and \textit{false} (0.0) otherwise.

The features used are : the log of the relative rank ($log \frac{rank}{|L|}$) and the score of the link.
The first feature to take into account that true links are generally on the top of the rank list.
The value is normalized to be able to generalize this value to any rank list size.
The logarithm allow to have a greater contrast in value for the top rank while considering bottom rank as more or less equal.
The second feature aim to consider that the small distances are generally true links.

Using these two features, the model can grasp the importance of the rank and the score of each link.
Since the training is only based on the relative rank and the score at each rank, the trained model is language independent and size independent.
But this model is metric dependent, since the score magnitude can variate depending on the distance function.

In this study, the model used is the logistic regression.
The advantage of using a regression model is that the output of the model will correspond to a probability of being a true link according to the model.
To find the cut on the test datasets, the fitted model predict the probability of being a true link on every link in the new rank list.

From these predictions, a probability threshold must be chosen.
For example, having a probability threshold at $0.5$, minimize both false negatives and the false positives.
This can be adjusted in the case of cost minimization, for example if false negatives are more important to minimize, a probability threshold at $0.6$ can be selected instead or $0.4$ if the false positive should be minimized.
Which will subsequently either improve the $B^3_{recall}$ or the $B^3_{precision}$ when evaluating the clustering.
To optimize the $B^3_{F_1}$, the probability threshold should be $0.5$, since this metrics aim to optimize both the recall and the precision with the harmonic mean.

An impression caused by the fact that the rank list live in a discrete space, and the score in a continuous space arise.
The interpolation is one method to allow having a more accurate distance threshold.
To correctly separate true links from false links, the distance threshold is chosen by linearly interpolating the probability threshold to the scores with the closest probabilities, respectively, the one directly above and the one directly below the threshold.
Example~\ref{ex:linear_interpolation} showcase a linear interpolation computation using a $0.5$ probability threshold.
The logistic regression model can be re-used on any other rank lists produced with the same distance metrics.

\begin{example}
  \centering
  \caption{Linear interpolation for regression-based clustering distance threshold selection (probability threshold fixed at 0.5)}
  \label{ex:linear_interpolation}

  \begin{subexample}{\linewidth}
    \centering
    \subcaption{Rank list with link probability and score}
    \begin{tabular}{l r r}
      \toprule
      Rank & Probability & Score \\
      \midrule
      (...) & &\\
      45th & 0.54 & 15 \\
      46th & 0.52 & 13 \\
      47th & 0.49 & 12 \\
      48th & 0.48 & 10 \\
      (...) & & \\
      \bottomrule
    \end{tabular}
  \end{subexample}

  \vspace{0.5cm}

  \begin{subexample}{\linewidth}
    \centering
    \subcaption{Linear interpolation}
    \begin{align}
        \alpha &= \frac{0.5 - 0.49}{0.52 - 0.49} = \frac{1}{3} \\
        \textit{distance\_threshold}_{@0.5} &= (13 - 12) \cdot \alpha + 12 = 12 + \frac{1}{3}
    \end{align}
  \end{subexample}
\end{example}


\subsection{Evaluation}

To evaluate the regression-based clustering approach: the Oxquarry, Brunet, St-Jean A and B corpora were used.
The same approach as for the distribution-based clustering is used.
Each retained rank list for each corpus is computed, see Table~\ref{tab:rls_oxquarry_brunet}~and~\ref{tab:rls_st_jean} in annex.
For each rank list pair, the distance threshold is computed, using the logistic regression approach.
This step corresponds to the training phase.
Then for every distance threshold and rank list pair, the clustering is evaluated using the $B^3_{F_1}$ and the $r_{diff}$.
This corresponds to the testing phase.
In other words, a model to create cuts is trained on every corpus and tested on all the corpora.

The BCubed metrics and the r ratio difference are computed during this experiment and are presented in Table~\ref{tab:regression-based_clustering}, for every pair of datasets.
To aggregate the results, the arithmetic mean for $B^3_{F_1}$ and $r_{diff}$ across all retained rank list is computed.

The following conclusions can be drawn with these results:
\begin{itemize}
  \item
  The best linkage criterion for this model is the average linkage with a $B^3_{F_1} = 0.80$.
  \item
  Some corpus such as the Oxquarry corpus have better rank list for training the clustering model even though their rank list have a worse average precision than other corpora.
  When training with Oxquarry corpus, the $B^3_{F_1}$ is in average 8 to 10\% better than the ones trained with the Brunet corpus.
  This indicates that the training set does not necessarily require a high quality rank list for training the clustering model.
  \item
  When testing the cut model, having a rank list of good quality tends to produce a better clustering, no matter the quality of the rank list used for the training.
  As shown in Section~\ref{sec:hierarchical_clustering}
  For example, when testing the clustering model on the corpus with the best rank list in average (St-Jean B), it obtains in average the best clustering, $B^3_{F_1} = 0.91$.
\end{itemize}

The conclusion to the previous points is that having a good rank list is more important for testing than training.
Though some corpus can be better than others for training.
No clear rank lists property was found, which makes some of them better to train the model.

\begin{table*}
  \centering
  \caption{Regression-based clustering evaluation, Mean retained rank lists $B^{3}_{F_1}$/$r_{diff}$ for each corpus pair}
  \label{tab:regression-based_clustering}

  \subcaption{Single Linkage}
  \begin{tabular}{l l| c c c c|c}
    \toprule
    \multicolumn{2}{c}{\multirow{2}{*}{}} & \multicolumn{4}{c}{Testing} \\
    \multicolumn{2}{c}{} & Oxquarry & Brunet & St-Jean A & St-Jean B & Mean \\
    \midrule
    \parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{Training}}}
    & Oxquarry  & 0.58/0.09 & 0.59/0.09 & 0.29/0.14 & 0.22/0.16 & 0.42/0.12 \\
    & Brunet    & 0.77/0.17 & 0.78/0.09 & 0.58/0.10 & 0.83/0.03 & 0.74/0.10 \\
    & St-Jean A & 0.79/0.14 & 0.77/0.06 & 0.50/0.09 & 0.69/0.07 & 0.69/0.09 \\
    & St-Jean B & 0.78/0.15 & 0.78/0.08 & 0.53/0.08 & 0.74/0.05 & 0.71/0.09 \\
    \midrule
    & Mean      & 0.73/0.14 & 0.73/0.08 & 0.48/0.10 & 0.62/0.08 & 0.64/0.10 \\
    \bottomrule
  \end{tabular}

  \vspace{0.5cm}

  \subcaption{Average Linkage}
  \begin{tabular}{l l| c c c c|c}
    \toprule
    \multicolumn{2}{c}{\multirow{2}{*}{}} & \multicolumn{4}{c}{Testing} \\
    \multicolumn{2}{c}{} & Oxquarry & Brunet & St-Jean A & St-Jean B & Mean \\
    \midrule
    \parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{Training}}}
    & Oxquarry  & 0.83/0.11 & 0.80/0.11 & 0.83/0.04 & 0.91/0.01 & 0.84/0.07 \\
    & Brunet    & 0.72/0.22 & 0.75/0.20 & 0.73/0.15 & 0.89/0.07 & 0.77/0.16 \\
    & St-Jean A & 0.73/0.21 & 0.76/0.17 & 0.76/0.13 & 0.92/0.05 & 0.79/0.14 \\
    & St-Jean B & 0.72/0.21 & 0.75/0.19 & 0.75/0.13 & 0.92/0.05 & 0.79/0.15 \\
    \midrule
    & Mean      & 0.75 0.19 & 0.76 0.17 & 0.77 0.11 & 0.91 0.05 & 0.80/0.13 \\
    \bottomrule
  \end{tabular}

  \vspace{0.5cm}

  \subcaption{Complete Linkage}
  \begin{tabular}{l l| c c c c|c}
    \toprule
    \multicolumn{2}{c}{\multirow{2}{*}{}} & \multicolumn{4}{c}{Testing} \\
    \multicolumn{2}{c}{} & Oxquarry & Brunet & St-Jean A & St-Jean B & Mean \\
    \midrule
    \parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{Training}}}
    & Oxquarry  & 0.76/0.15 & 0.79/0.16 & 0.72/0.14 & 0.91/0.04 & 0.79/0.12 \\
    & Brunet    & 0.63/0.30 & 0.71/0.24 & 0.65/0.21 & 0.82/0.13 & 0.71/0.22 \\
    & St-Jean A & 0.66/0.27 & 0.73/0.23 & 0.67/0.19 & 0.85/0.10 & 0.73/0.20 \\
    & St-Jean B & 0.64/0.29 & 0.73/0.23 & 0.67/0.20 & 0.84/0.10 & 0.72/0.20 \\
    \midrule
    & Mean      & 0.67/0.25 & 0.74/0.22 & 0.68/0.19 & 0.86/0.09 & 0.74/0.19 \\
    \bottomrule
  \end{tabular}
\end{table*}
