\section{Regression-based clustering\label{sec:regression_based_clustering}}

\subsection{Method}

To learn at which position in the rank list the cut should be, this third idea is to train a linear model.
The model aim to learn to discriminate the same authors document pairs from different authors document pairs in a rank list.

To train the model, samples are created for each link in a training rank list.
The links labels are either \textit{true links} when both document in the link are from the same author or \textit{false link} otherwise.

The two features used are: the log of the link relative rank ($log \frac{link\_rank}{|L|}$) and the score of the link.

First feature provide to the model that true links are generally at the top of the rank list.
The value is normalized by the size of the rank list.
This allows to train in more generically manner, such that the model can be used to predict on any rank list size.
The logarithm scale is used to have a greater granularity for the top ranked links.

Second feature aim to provide to the model that the small distances or large similarities are generally true links.

Using these two features, the model can, depending on each link rank and the score, determinate if the link is a true link.
A model trained with these features does not depend on the text language nor the corpus size.
This model is metric dependent, since the score magnitude change according to the distance function.

In this study, the linear model used is the logistic regression.
The advantage of using a regression model is that the output of the model will correspond to a probability of being a true link.
To find the cut in the testing rank list, the fitted model predict the probability of being a true link for each link.
A trained logistic regression model can be used to predict true link probabilities on any other rank lists produced with the same distance metrics.

From these predictions, a probability threshold must be chosen.
For example, having a probability threshold at $0.5$, aim to minimize both false negatives and the false positives.
The threshold used to optimize the $B^3_{F_1}$ should be $0.5$, since this metrics aim to optimize both the recall and the precision which respectively aim to minimize false negatives and false positives.

The probability threshold can be adjusted for a cost minimization case.
For example if false negatives are more important to minimize, a probability threshold at $0.6$ can be selected instead or $0.4$ if the false positive should be minimized.
Which will subsequently either improve the $B^3_{recall}$ or the $B^3_{precision}$ for the authorship clustering.

The distance threshold is selected according to the score of the closest link to the probability threshold.
With this method, the distance threshold can be imprecise.
This is caused by the fact that the rank list is in a discrete space and the score in a continuous space.
In other words, there might not be a link with a true link probability of $0.5$ and the distance threshold will not be selected properly with this method.

One way to find a slightly more accurate distance threshold is to use a linear interpolation.
The score is interpolated to the true links probabilities the closest to the threshold, respectively, the one directly above and the one directly below in the rank list.
Example~\ref{ex:linear_interpolation} showcase a linear interpolation of the score using a $0.5$ probability threshold in a synthetic rank list.

\begin{example}
  \centering
  \caption{Linear interpolation for regression-based clustering distance threshold selection (probability threshold fixed at 0.5)}
  \label{ex:linear_interpolation}

  \begin{subexample}{\linewidth}
    \centering
    \subcaption{Rank list with link probability and score}
    \begin{tabular}{l r r}
      \toprule
      Rank & Probability & Score \\
      \midrule
      (...) & &\\
      45th & 0.54 & 15 \\
      46th & 0.52 & 13 \\
      47th & 0.49 & 12 \\
      48th & 0.48 & 10 \\
      (...) & & \\
      \bottomrule
    \end{tabular}
  \end{subexample}

  \vspace{0.5cm}

  \begin{subexample}{\linewidth}
    \centering
    \subcaption{Linear interpolation}
    \begin{align*}
        \alpha &= \frac{0.5 - 0.49}{0.52 - 0.49} = \frac{1}{3} \\
        \textit{distance\_threshold}_{@0.5} &= (13 - 12) \cdot \alpha + 12 = 12.\bar{3}
    \end{align*}
  \end{subexample}
\end{example}


\subsection{Evaluation}

To evaluate the regression-based clustering approach: the Oxquarry, Brunet, St-Jean A and B corpora were used.

Each retained rank list for each corpus is computed and used for the experiment, see their evaluation in Table~\ref{tab:rls_oxquarry_brunet}~and~\ref{tab:rls_st_jean} in annex.
A logistic regression model is trained with each rank list.
This step corresponds to the training phase.

Then the trained models are used to predict a distance threshold for the rank list with the same distance metrics.
The hierarchical clustering is applied to the rank list using the distance threshold predicted.
The clustering result is evaluated using the $B^3_{F_1}$ and the $r_{diff}$.
In other words, a model to find distance threshold is trained on every rank list from every corpus and tested on every rank list from every corpus.
This corresponds to the testing phase.

The experiment is repeated for each linkage criterion.

The results are presented in Table~\ref{tab:regression-based_clustering}.
The results are aggregated using the arithmetic mean on the $B^3_{F_1}$ and $r_{diff}$ on all retained rank list per corpus as shown in Figure~\ref{fig:clustering_evaluation_methodology} in Section~\ref{sec:hierarchical_clustering}.

The following conclusions can be drawn with these results:
\begin{itemize}
  \item
  The best linkage criterion for this model is the average linkage with an average $B^3_{F_1} = 0.80$.
  The average linkage have a relative $B^3_{F_1}$ increase of $20\%$ over the single linkage and $8\%$ over the complete linkage.
  \item
  Some corpus such as the Oxquarry corpus have better rank list for training the clustering model even though their rank list have a worse average precision than other corpora.
  When training with Oxquarry corpus with the average linkage, the $B^3_{F_1}$ is $9\%$ better than the ones trained with the Brunet corpus.
  This indicates that the training set does not necessarily require a high quality rank list to train the clustering model.
  \item
  When testing the cut model, having a rank list of good quality tends to produce a better clustering, no matter the quality of the rank list used for the training.
  As shown in Section~\ref{sec:hierarchical_clustering}.
  For example, when testing the clustering model on the corpus with the best rank list in average (St-Jean B), it obtains in average the best clustering, $B^3_{F_1} = 0.91$.
\end{itemize}

The conclusion to the previous points is that having a good rank list is more important for testing than training.
Though some corpus can be better than others for training.
No clear rank lists property was found, which makes them better to train the model over others.

\begin{table*}
  \centering
  \caption{Regression-based clustering evaluation, Mean retained rank lists $B^{3}_{F_1}$/$r_{diff}$ for each corpus pair}
  \label{tab:regression-based_clustering}

  \subcaption{Single Linkage}
  \begin{tabular}{l l| c c c c|c}
    \toprule
    \multicolumn{2}{c}{\multirow{2}{*}{}} & \multicolumn{4}{c}{Testing} \\
    \multicolumn{2}{c}{} & Oxquarry & Brunet & St-Jean A & St-Jean B & Mean \\
    \midrule
    \parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{Training}}}
    & Oxquarry  & 0.58/0.09 & 0.59/0.09 & 0.29/0.14 & 0.22/0.16 & 0.42/0.12 \\
    & Brunet    & 0.77/0.17 & 0.78/0.09 & 0.58/0.10 & 0.83/0.03 & 0.74/0.10 \\
    & St-Jean A & 0.79/0.14 & 0.77/0.06 & 0.50/0.09 & 0.69/0.07 & 0.69/0.09 \\
    & St-Jean B & 0.78/0.15 & 0.78/0.08 & 0.53/0.08 & 0.74/0.05 & 0.71/0.09 \\
    \midrule
    & Mean      & 0.73/0.14 & 0.73/0.08 & 0.48/0.10 & 0.62/0.08 & 0.64/0.10 \\
    \bottomrule
  \end{tabular}

  \vspace{0.5cm}

  \subcaption{Average Linkage}
  \begin{tabular}{l l| c c c c|c}
    \toprule
    \multicolumn{2}{c}{\multirow{2}{*}{}} & \multicolumn{4}{c}{Testing} \\
    \multicolumn{2}{c}{} & Oxquarry & Brunet & St-Jean A & St-Jean B & Mean \\
    \midrule
    \parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{Training}}}
    & Oxquarry  & 0.83/0.11 & 0.80/0.11 & 0.83/0.04 & 0.91/0.01 & 0.84/0.07 \\
    & Brunet    & 0.72/0.22 & 0.75/0.20 & 0.73/0.15 & 0.89/0.07 & 0.77/0.16 \\
    & St-Jean A & 0.73/0.21 & 0.76/0.17 & 0.76/0.13 & 0.92/0.05 & 0.79/0.14 \\
    & St-Jean B & 0.72/0.21 & 0.75/0.19 & 0.75/0.13 & 0.92/0.05 & 0.79/0.15 \\
    \midrule
    & Mean      & 0.75 0.19 & 0.76 0.17 & 0.77 0.11 & 0.91 0.05 & 0.80/0.13 \\
    \bottomrule
  \end{tabular}

  \vspace{0.5cm}

  \subcaption{Complete Linkage}
  \begin{tabular}{l l| c c c c|c}
    \toprule
    \multicolumn{2}{c}{\multirow{2}{*}{}} & \multicolumn{4}{c}{Testing} \\
    \multicolumn{2}{c}{} & Oxquarry & Brunet & St-Jean A & St-Jean B & Mean \\
    \midrule
    \parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{Training}}}
    & Oxquarry  & 0.76/0.15 & 0.79/0.16 & 0.72/0.14 & 0.91/0.04 & 0.79/0.12 \\
    & Brunet    & 0.63/0.30 & 0.71/0.24 & 0.65/0.21 & 0.82/0.13 & 0.71/0.22 \\
    & St-Jean A & 0.66/0.27 & 0.73/0.23 & 0.67/0.19 & 0.85/0.10 & 0.73/0.20 \\
    & St-Jean B & 0.64/0.29 & 0.73/0.23 & 0.67/0.20 & 0.84/0.10 & 0.72/0.20 \\
    \midrule
    & Mean      & 0.67/0.25 & 0.74/0.22 & 0.68/0.19 & 0.86/0.09 & 0.74/0.19 \\
    \bottomrule
  \end{tabular}
\end{table*}
