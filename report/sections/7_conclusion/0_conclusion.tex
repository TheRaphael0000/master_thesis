\chapter{Conclusion and Future Work\label{sec:conclusion}}

% \section{Conclusion}

Evaluation is an important aspect to improve our knowledge.
In this view, this study is based on three known collections namely Oxquarry, Brunet and St-Jean.
These three corpora containing excepts of literature novels.
Nine different techniques to produce individual rank lists are cherry-picked for the clustering and fusion steps.
These techniques are mostly based on the most frequent words.
Compression techniques are also evaluated and used.

Once each intermediate representations of the corpora, namely the rank lists, are created and evaluated.
A hierarchical clustering model is applied.
With this model, a cut in the rank list which discriminate the same authors documents to different authors documents is required.
Three solutions to find the cut best position are proposed.

The first is a fully unsupervised method based on the Silhouette Score.
We added an extra hyperparameter to the Silhouette-based clustering and tweaked it for the authorship clustering problem.
By doing so, this model improves its clustering results in average by $7\%$ across the three corpora.

The second is a supervised method and thus require a corpus with labels to calibrate the system.
We called this method distribution-based.
This method output a single numerical value which is used to perform the cut for any subsequent corpus.
This strategy gives the best results for the individual methods.

The last technique to perform the cut is also supervised and is based on a logistic regression model.
For any new corpus, this model is used to predict the best position in the rank list for the cut.

The three methods to find the cut for the hierarchical clustering give good results close to the best clustering achievable for the rank lists used.
Additionally, we demonstrated a correlation between the rank lists quality and the clustering quality.

In a second part of this study, two rank lists' fusion method are proposed and evaluated.
This proposition come from the idea that combining good rank lists can give one better than each individual one.
One fusion technique uses the Z-Score normalization and the other one convert the rank list scores into probabilities using multiple logistic regression.
The Z-Score fusion technique show a significant improvement of the results when compared to the best rank list used for the fusion.
Whereas the logistic regression fusion procedure give slightly worse results but still shown a significant stabilization of the results.
The rank list produced with the logistic regression fusion give a rank list quality equivalent to the average quality of the rank list used.
These results motivate the rank lists' fusion's beneficial aspect for unsupervised task such as the authorship clustering problem.

Two veto-based techniques are proposed and evaluated to try to further improve the fused rank list's quality.
No real improvements are found using the proposed veto strategies on high quality rank lists (more than $0.7$ in AP).

To further motivate the strength of the rank lists' fusions, we showed a correlation between the rank lists' variety and the improvements provided when fusing rank lists.
We showed that by using for the fusion, rank lists produced along different text representations increase more the effectiveness of resulting rank list than using rank lists with the same text representation but with different distance measures.

At the end of this study, we evaluated the clustering using the rank list obtained by fusion.
As we expected from previous results, the clustering obtained with the rank lists obtained by Z-Score fusion is better than the individual methods.
We obtained overall a $6\%$ improvement using the Z-Score fusion over the individual methods.
This improvement in the clustering is due to the fact that the rank lists obtained by fusion are better than the ones obtained by individual methods and thus, as we showed previously, having good rank lists tends to produce good clusterings.
The tweaked Silhouette-based clustering unsupervised method gives the best results for the rank lists obtained by Z-Score fusion.

% \section{Future Work}

The authorship clustering models used still need to be compared to other models from the state of the art.
This can be done by testing this model with corpora written in other languages or extracted from domains or support (e.g. blogs), which were also used for this task.

As the literature shows, many methods to generate rank lists are possible.
We showed that using for the fusion diverse individual technique improve the results.
Thus, testing our current fusion schemes with other individual methods, could potentially further improve the results.

The $N$-First characters text representation gave outstanding results on some corpora.
Though it was not retained for the fusion, since for other corpora it gave poor results.
A deeper analysis has to be made for this text representation.

Another point not treated in this study is to use compression techniques with different text representation.
The POS sequences seem a good choice to explore with compression techniques.

Other fusion methods still need to be tested to potentially further increase the fusions quality.
For example: other normalization techniques can be used and/or other ways to compute a central tendency (e.g. the geometric mean or the harmonic mean).

Veto-based technique were experimented to force bottom ranked links according to one rank list to the bottom of a fused rank list.
Another alternative to this veto, could be to force top rank lists, to be at the top of the fused rank list.
This technique may improve the results.
